{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BPMOGA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlK6Vj_sHiNj",
        "colab_type": "text"
      },
      "source": [
        "**Bi-Phased Multi Objective Genetic Algorithm (BPMOGA)** \\\\\n",
        "This is Python implementation of BPMOGA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-FQEDHGNjGY",
        "colab_type": "text"
      },
      "source": [
        "**Import Section**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ore-LinZNdPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import copy\n",
        "#import time\n",
        "import math\n",
        "#import matplotlib.pyplot as plt"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23SHPsP5eEDt",
        "colab_type": "text"
      },
      "source": [
        "**Deciding about the device**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWflRpGGeP6B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2ed1f624-2f65-40bc-c042-f3f16ec23217"
      },
      "source": [
        "print(\"Function deciding about the device\") # for testing\n",
        "print(\"-----------------------------\") # for testing\n",
        "def get_device():\n",
        "  if torch.cuda.is_available():\n",
        "    device = 'cuda:0'\n",
        "  else:\n",
        "    device = 'cpu'\n",
        "  return device\n",
        "device = get_device()\n",
        "print(\"We are using:\" + device) # for testing\n",
        "print(\"-----------------------------\") # for testing"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Function deciding about the device\n",
            "-----------------------------\n",
            "We are using:cuda:0\n",
            "-----------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDm25Igjd_Ab",
        "colab_type": "text"
      },
      "source": [
        "**Storing data into data frame from .csv files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axyKaiM7hInc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "936872d7-fe45-4449-99e4-19f069658708"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/Dipankar2222/Datasets/master/Test/INPUT_FILES/Original.data', header = None)# for testing\n",
        "print(df.to_string()) # for testing"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       0   1         2\n",
            "0   99.4   C    Absent\n",
            "1   99.5   B    Absent\n",
            "2   98.7   A   Present\n",
            "3  100.0   C    Absent\n",
            "4   99.0   C    Absent\n",
            "5   99.2   B    Absent\n",
            "6   98.9   B   Present\n",
            "7   98.5   A   Present\n",
            "8   98.9   A   Present\n",
            "9   99.8   A   Present\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNT-6a69RI6u",
        "colab_type": "text"
      },
      "source": [
        "**Dataset class. For storing different attribute values and Preprocessing data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkD3UMS-zUBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset:  \n",
        "  \n",
        "  def __init__(self,train_list,test_list,attribute_information): \n",
        "    #self.train_list = train_list\n",
        "    #self.test_list = test_list\n",
        "    #self.attribute_information = attribute_information \n",
        "    # print(\"Train data of 1st fold\") # for testing\n",
        "    # print(train_list[0].to_string()) # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.no_of_records_in_train_list = self.find_no_of_records(train_list)\n",
        "    # print('Records in train data sets')\n",
        "    # print(*no_of_records_in_train_list, sep = \", \")\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.no_of_records_in_test_list = self.find_no_of_records(test_list)\n",
        "    # print('Records in test data sets')\n",
        "    # print(*no_of_records_in_test_list, sep = \", \")\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.no_of_attributes = self.find_no_of_attributes(attribute_information)    \n",
        "    # print('Number of attributes='+str(no_of_attributes))    \n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing     \n",
        "    self.train_list_with_NaN = self.replacing_missing_values_with_NaN(train_list)\n",
        "    # print(\"Train data of 1st fold with NaN\") # for testing\n",
        "    # print(train_list_with_NaN[0].to_string()) # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.test_list_with_NaN = self.replacing_missing_values_with_NaN(test_list)\n",
        "    # print(\"Test data of 1st fold with NaN\") # for testing\n",
        "    # print(test_list_with_NaN[0].to_string()) # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.types_of_attributes = self.find_types_of_attributes(self.train_list_with_NaN[0])\n",
        "    # print(\"Types of attributes\") # for testing\n",
        "    # print(*self.types_of_attributes, sep = ',') # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.min_value_for_train_numerical_feature = self.find_min_values_for_numerical_features(self.train_list_with_NaN)\n",
        "    # print('Min values in train data sets')\n",
        "    # print(self.min_value_for_train_numerical_feature[0]) # for testing\n",
        "    # print(*self.min_value_for_train_numerical_feature[0], sep = \",\\n\")\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.max_value_for_train_numerical_feature = self.find_max_values_for_numerical_features(self.train_list_with_NaN)\n",
        "    # print('Max values in train data sets')\n",
        "    # print(self.max_value_for_train_numerical_feature[0]) # for testing\n",
        "    # print(*self.max_value_for_train_numerical_feature[0], sep = \",\\n\")\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing    \n",
        "    # normalized_train_list = self.normalize(train_list_with_NaN) # I have not done normalization in BPMOGA paper\n",
        "    # print(\"Normalized Train data of 1st fold\") # for testing\n",
        "    # print(normalized_train_list[1].to_string()) # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    # normalized_test_list = self.normalize(test_list_with_NaN) # I have not done normalization in BPMOGA paper\n",
        "    # print(\"Normalized Test data of 1st fold\") # for testing\n",
        "    # print(normalized_test_list[0].to_string()) # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.sorted_unique_attribute_values_of_train_dataset = self.store_sorted_unique_attribute_values(self.train_list_with_NaN)\n",
        "    # print(\"Unique attribute values of train data set of 1st fold\") # for testing\n",
        "    # print(*self.sorted_unique_attribute_values_of_train_dataset[0], sep = ',\\n') # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.no_of_different_attribute_values = self.find_no_of_different_attribute_values(self.sorted_unique_attribute_values_of_train_dataset)\n",
        "    # print(\"No of different attribute values in train data set of 1st fold\") # for testing\n",
        "    # print(self.no_of_different_attribute_values[0][0]) # for testing\n",
        "    # print(*self.no_of_different_attribute_values[0], sep = ',') # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.class_labels = self.find_class_labels(self.sorted_unique_attribute_values_of_train_dataset)\n",
        "    # print(\"Class labels in train data set of 1st fold\") # for testing\n",
        "    # print(*self.class_labels[0], sep = ',') # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.no_of_classes = self.find_no_of_classes(self.class_labels)\n",
        "    # print(\"No of classes in train data sets\") # for testing\n",
        "    # print('no_of_classes=' + str(no_of_classes[0])) # for testing\n",
        "    # print(*no_of_classes, sep = ',') # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.change_points_of_train_data_set = self.find_change_points(self.train_list_with_NaN,self.min_value_for_train_numerical_feature,self.max_value_for_train_numerical_feature)\n",
        "    # print(\"change points of train data set of 1st fold\") # for testing\n",
        "    # print(*self.change_points_of_train_data_set[0], sep = ',\\n') # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing    \n",
        "    # probability_of_class = self.find_probability_of_class(train_list_with_NaN[0],no_of_records_in_train_list[0],'0.0')\n",
        "    #class_entropy_list = self.find_entropy_of_class(self.train_list_with_NaN,self.no_of_records_in_train_list,self.class_labels,self.no_of_classes)\n",
        "    #print(\"class entropy list of train data set of 1st fold\") # for testing\n",
        "    #print(*class_entropy_list, sep = ',') # for testing\n",
        "    #print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    # interval_and_class_probability = self.calculate_probability_of_an_interval_and_class(train_list_with_NaN[0],'0.0',0.1,0.1,0)\n",
        "    # average_interval_and_class_entropy = self.calculate_entropy_of_mumeric_attribute(train_list_with_NaN[0],class_labels[0],0,change_points_of_train_data_set[0][0],no_of_classes[0])\n",
        "    # average_interval_and_class_entropy = self.calculate_entropy_of_categorical_attribute(train_list_with_NaN[1],class_labels[1],1,no_of_classes[1],no_of_different_attribute_values[1][1],sorted_unique_attribute_values_of_train_dataset[1][1])\n",
        "    # self.calculate_entropy_of_numeric_attribute(train_list_with_NaN[0],class_labels[0],0,change_points_of_train_data_set[0][0],no_of_classes[0])\n",
        "    entropy_list = self.find_entropy(self.train_list_with_NaN,self.no_of_records_in_train_list,self.class_labels,self.no_of_classes,self.no_of_attributes,self.change_points_of_train_data_set,self.no_of_different_attribute_values,self.sorted_unique_attribute_values_of_train_dataset)\n",
        "    # print(\"entropy list of train data set of 1st fold\") # for testing\n",
        "    # print(*entropy_list[1], sep = ',') # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    information_gain_list = self.find_information_gain(entropy_list,self.no_of_attributes)\n",
        "    #print(\"information gain list of train data set of 1st fold\") # for testing\n",
        "    #print(*information_gain_list[0], sep = ',') # for testing\n",
        "    #print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    self.attribute_selection_probability_list = self.calculate_attribute_selection_probability(information_gain_list,self.no_of_attributes)\n",
        "    # print(\"attribute selection probability list of train data set of 1st fold\") # for testing\n",
        "    # print(*self.attribute_selection_probability_list[0], sep = ',') # for testing\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "\n",
        "\n",
        "  def find_no_of_records(self,t_list):\n",
        "    no_of_records = [] # no_of_records stores 10 no of records in data sets      \n",
        "    for i in range(0, 10):\n",
        "      no_of_records.append(t_list[i].shape[0])      \n",
        "    return no_of_records\n",
        "\n",
        "\n",
        "  def find_no_of_attributes(self,attribute_information):\n",
        "    no_of_attributes =  attribute_information.shape[1]           \n",
        "    return no_of_attributes\n",
        "\n",
        "\n",
        "  def replacing_missing_values_with_NaN(self,t_list):\n",
        "    t_list_with_NaN = []\n",
        "    for i in range(0, 10):          \n",
        "      t_list_modified = t_list[i].copy(deep = True) # to create a copy to avoid passing by reference\n",
        "      t_list_modified.replace('?', np.nan, inplace = True)\n",
        "      for i in t_list_modified.columns:\n",
        "        t_list_modified[i] = pd.to_numeric(t_list_modified[i], errors='ignore')\n",
        "      t_list_with_NaN.append(t_list_modified)\n",
        "    return t_list_with_NaN\n",
        "\n",
        "\n",
        "  def find_types_of_attributes(self,t_dataset):\n",
        "    data_types = t_dataset.dtypes\n",
        "    return data_types\n",
        "\n",
        "\n",
        "  def find_min_values_for_numerical_features(self,t_list):\n",
        "    t_numerical_features = []    \n",
        "    no_of_numerical_columns_for_t = []    \n",
        "    min_value_for_t_numerical_feature = []\n",
        "    for i in range(0, 10):\n",
        "      t_numerical_features.append(t_list[i]._get_numeric_data())      \n",
        "      min_value_for_t_numerical_feature.append(t_numerical_features[i].min())        \n",
        "    return min_value_for_t_numerical_feature\n",
        "\n",
        "\n",
        "  def find_max_values_for_numerical_features(self,t_list):\n",
        "    t_numerical_features = []    \n",
        "    no_of_numerical_columns_for_t = []    \n",
        "    max_value_for_t_numerical_feature = []\n",
        "    for i in range(0, 10):\n",
        "      t_numerical_features.append(t_list[i]._get_numeric_data())          \n",
        "      max_value_for_t_numerical_feature.append(t_numerical_features[i].max())        \n",
        "    return max_value_for_t_numerical_feature\n",
        "\n",
        "\n",
        "  def normalize(self,t_list):\n",
        "    normalized_t_list = []\n",
        "    for i in range(0, 10):\n",
        "      # print('i='+str(i))\n",
        "      train_features = t_list[i].copy(deep = True)\n",
        "      # print(t_list[i])\n",
        "      train_numerical_features = t_list[i]._get_numeric_data()        \n",
        "      value_range = train_numerical_features.max() - train_numerical_features.min()\n",
        "      min_value = train_numerical_features.min()\n",
        "      train_normalized_numerical_features = train_numerical_features.copy(deep = True) # to create a copy to avoid passing by reference\n",
        "      train_normalized_numerical_features = (train_numerical_features - min_value) / value_range\n",
        "      # print(train_normalized_numerical_features)\n",
        "      numerical_columns = list(set(train_numerical_features.columns).intersection(set(train_numerical_features.columns)))\n",
        "      train_features[numerical_columns] = train_normalized_numerical_features\n",
        "      # print(train_features.to_string())\n",
        "      normalized_t_list.append(train_features)      \n",
        "    return normalized_t_list\n",
        "\n",
        "\n",
        "  def store_sorted_unique_attribute_values(self,t_list):\n",
        "    sorted_unique_attribute_values = []\n",
        "    data_types = t_list[0].dtypes\n",
        "    for i in range(0, 10):  \n",
        "      unique_values = [] \n",
        "      for j in range(0, t_list[i].shape[1]):\n",
        "        unique_attribute_values_of_an_attribute = t_list[i][j].unique()         \n",
        "        if (data_types[j] == 'float64'):         \n",
        "          sorted_unique_attribute_values_of_an_attribute = np.sort(unique_attribute_values_of_an_attribute)           \n",
        "          unique_values.append(sorted_unique_attribute_values_of_an_attribute)\n",
        "        else:\n",
        "          unique_values.append(unique_attribute_values_of_an_attribute)\n",
        "      sorted_unique_attribute_values.append(unique_values)          \n",
        "    return sorted_unique_attribute_values\n",
        "\n",
        "\n",
        "  def find_no_of_different_attribute_values(self,sorted_unique_attribute_values):\n",
        "    no_of_different_attribute_values = []\n",
        "    for i in range(0, 10):\n",
        "      no_of_different_attribute_values_for_any_fold = []      \n",
        "      for j in range(0, len(sorted_unique_attribute_values[i])):        \n",
        "        no_of_different_attribute_values_for_any_fold.append(len(sorted_unique_attribute_values[i][j]))\n",
        "      no_of_different_attribute_values.append(no_of_different_attribute_values_for_any_fold)\n",
        "    return no_of_different_attribute_values\n",
        "\n",
        "\n",
        "  def find_class_labels(self,sorted_unique_attribute_values):\n",
        "    class_labels = []\n",
        "    for i in range(0, 10):\n",
        "      class_labels.append(sorted_unique_attribute_values[i][len(sorted_unique_attribute_values[i])-1])      \n",
        "    return class_labels\n",
        "\n",
        "\n",
        "  def find_no_of_classes(self,class_labels):\n",
        "    no_of_classes = []\n",
        "    for i in range(0, 10):\n",
        "      no_of_classes.append(len(class_labels[i]))      \n",
        "    return no_of_classes \n",
        "\n",
        "\n",
        "  def find_change_points(self,t_list,min_value_for_t_numerical_feature,max_value_for_t_numerical_feature):    \n",
        "    change_points = []\n",
        "    change_points1 = []\n",
        "    data_types = t_list[0].dtypes\n",
        "    for i in range(0, 10):\n",
        "      # print(t_list[i].shape[1])\n",
        "      change_points_of_a_fold = []\n",
        "      # l = -1\n",
        "      for j in range(0, t_list[i].shape[1]-1): \n",
        "        change_points_with_duplicate = []        \n",
        "        if (data_types[j] == 'float64'):  \n",
        "          # l = l+1          \n",
        "          attribute_and_class = t_list[i].iloc[:, [j,t_list[i].shape[1]-1]].copy(deep = True) # to create a copy to avoid passing by reference         \n",
        "          # print(attribute_and_class)\n",
        "          attribute_and_class = attribute_and_class.sort_index().sort_values(by = [j],kind='mergesort').copy(deep = True) # to create a copy to avoid passing by reference           \n",
        "          # if (j==8):\n",
        "           # print(attribute_and_class.to_string())\n",
        "          attributevalue_1 = attribute_and_class.iat[0, 0]\n",
        "          classLabel_1 = attribute_and_class.iat[0, 1]\n",
        "          # print(attributevalue_1)\n",
        "          # print(classLabel_1)\n",
        "          # print(t_list[i].shape[0])\n",
        "          change_points_with_duplicate = []\n",
        "          for k in range(1, t_list[i].shape[0]): \n",
        "            attributevalue_2 = attribute_and_class.iat[k, 0]\n",
        "            classLabel_2 = attribute_and_class.iat[k, 1]\n",
        "            # print(attributevalue_2)\n",
        "            # print(classLabel_2)\n",
        "            if (classLabel_1 != classLabel_2):\n",
        "              if (attributevalue_1 != attributevalue_2):\n",
        "                change_point = (attributevalue_1 + attributevalue_2) / 2.0   \n",
        "                # if(j==8):             \n",
        "                  # print('change_point=' + str(change_point))\n",
        "                change_points_with_duplicate.append(change_point)\n",
        "            attributevalue_1 = attribute_and_class.iat[k, 0]\n",
        "            classLabel_1 = attribute_and_class.iat[k, 1]              \n",
        "          # print('l='+str(l))\n",
        "          # print('max_value_for_t_numerical_feature[i][l]='+max_value_for_t_numerical_feature[i,l])\n",
        "          change_points_with_duplicate.insert(0,min_value_for_t_numerical_feature[i][j])\n",
        "          change_points_with_duplicate.append(max_value_for_t_numerical_feature[i][j])\n",
        "        # print (*change_points_with_duplicate, ',')          \n",
        "        change_points_of_a_fold.append(change_points_with_duplicate)\n",
        "      change_points.append(change_points_of_a_fold)\n",
        "    for i in range(0, 10):\n",
        "      change_points_of_a_fold1 = []\n",
        "      for j in range(0, t_list[i].shape[1]-1): \n",
        "        change_points_of_an_attribute1 = []\n",
        "        if (data_types[j] == 'float64'): \n",
        "          change_points_of_an_attribute = change_points[i][j]\n",
        "          change_points_of_an_attribute1 = [x for x in change_points_of_an_attribute if str(x) != 'nan']\n",
        "          # print(*change_points_of_an_attribute1, sep = ',') # for testing\n",
        "          # change_points_of_an_attribute2 = []\n",
        "          # [change_points_of_an_attribute2.append(x) for x in change_points_of_an_attribute1 if x not in change_points_of_an_attribute2]\n",
        "          # print(*change_points_of_an_attribute2, sep = ',') # for testing\n",
        "        change_points_of_a_fold1.append(change_points_of_an_attribute1)\n",
        "      change_points1.append(change_points_of_a_fold1)          \n",
        "    return change_points1\n",
        "\n",
        "\n",
        "  def find_entropy(self,t_list,no_of_records_in_train_list,class_labels,no_of_classes,no_of_attributes,change_points_of_train_data_set,no_of_different_attribute_values,sorted_unique_attribute_values_of_train_dataset): \n",
        "    class_entropy_list = self.find_entropy_of_class(t_list,no_of_records_in_train_list,class_labels,no_of_classes) \n",
        "    entropy_list = []\n",
        "    data_types = t_list[0].dtypes\n",
        "    for i in range(0, 10):\n",
        "      # print('i='+str(i))\n",
        "      entropy_of_attributes = []\n",
        "      for j in range(0, no_of_attributes-1):\n",
        "        # print('j='+str(j))\n",
        "        if (data_types[j] == 'float64'): \n",
        "          entropy_of_numeric_attribute = self.calculate_entropy_of_numeric_attribute(t_list[i],class_labels[i],j,change_points_of_train_data_set[i][j],no_of_classes[i])  \n",
        "          entropy_of_attributes.append(entropy_of_numeric_attribute)\n",
        "        else:\n",
        "          entropy_of_categorical_attribute = self.calculate_entropy_of_categorical_attribute(t_list[i],class_labels[i],j,no_of_classes[i],no_of_different_attribute_values[i][j],sorted_unique_attribute_values_of_train_dataset[i][j])\n",
        "          entropy_of_attributes.append(entropy_of_categorical_attribute)\n",
        "      entropy_of_attributes.append(class_entropy_list[i])\n",
        "      entropy_list.append(entropy_of_attributes)\n",
        "    return entropy_list\n",
        "\n",
        "\n",
        "\n",
        "  def find_entropy_of_class(self,t_list,no_of_records_in_train_list,class_labels,no_of_classes):      \n",
        "    class_entropy_list = []\n",
        "    for i in range(0, 10):\n",
        "      # print('Fold=' + str(i)) # for testing\n",
        "      class_entropy = 0.0\n",
        "      for j in range(0, no_of_classes[i]):\n",
        "        probability_of_class = self.find_probability_of_class(t_list[i],no_of_records_in_train_list[i],class_labels[i][j])\n",
        "        class_entropy = class_entropy - probability_of_class * math.log2(probability_of_class)\n",
        "      # print('class_entropy=' + str(class_entropy)) # for testing\n",
        "      class_entropy_list.append(class_entropy)\n",
        "    return class_entropy_list\n",
        "\n",
        "\n",
        "\n",
        "  def find_probability_of_class(self,t_dataset,no_of_records,class_label):      \n",
        "    class_label_count = 0\n",
        "    # print('class_label=' + str(class_label)) # for testing    \n",
        "    for i in range(0, no_of_records):\n",
        "      # print('t_dataset.iat[i, t_dataset.shape[1]-1]=' + str(t_dataset.iat[i, t_dataset.shape[1]-1])) # for testing    \n",
        "      if(str(t_dataset.iat[i, t_dataset.shape[1]-1]) == str(class_label)):\n",
        "        class_label_count = class_label_count + 1\n",
        "    # print('class_label_count=' + str(class_label_count)) # for testing\n",
        "    # print('no_of_records=' + str(no_of_records)) # for testing    \n",
        "    class_probability = class_label_count/no_of_records\n",
        "    # print('probability_of_class=' + str(class_probability)) # for testing\n",
        "    return class_probability\n",
        "\n",
        "\n",
        "  def calculate_entropy_of_numeric_attribute(self,t_dataset,class_labels,attribute_no,change_points,no_of_classes):\n",
        "    # print ('attribute_no='+str(attribute_no))\n",
        "    average_interval_and_class_entropy = 0.0\n",
        "    no_of_intervals=len(change_points)-1\n",
        "    # print ('no_of_intervals='+str(no_of_intervals))\n",
        "    for i in range(0, no_of_intervals):\n",
        "      min_value_of_interval = change_points[i]\n",
        "      max_value_of_interval = change_points[i+1]\n",
        "      # print ('min_value_of_interval='+str(min_value_of_interval))\n",
        "      # print ('max_value_of_interval='+str(max_value_of_interval))\n",
        "      interval_and_class_entropy=0.0\n",
        "      # print ('no_of_classes='+str(no_of_classes))\n",
        "      for j in range(0, no_of_classes):\n",
        "        # print ('Class number='+str(j))\n",
        "        interval_and_class_probability = self.calculate_probability_of_an_interval_and_class(t_dataset,class_labels[j],min_value_of_interval,max_value_of_interval,attribute_no)\n",
        "        # print ('interval_and_class_probability='+str(interval_and_class_probability))\n",
        "        if(interval_and_class_probability>0.0):\n",
        "          interval_and_class_entropy = interval_and_class_entropy - interval_and_class_probability*math.log2(interval_and_class_probability)\n",
        "          # print ('interval_and_class_entropy='+str(interval_and_class_entropy))\n",
        "      interval_value_count=self.calculate_interval_value_count(t_dataset,min_value_of_interval,max_value_of_interval,attribute_no)\n",
        "      # print ('interval_value_count='+str(interval_value_count))\n",
        "      average_interval_and_class_entropy = average_interval_and_class_entropy + interval_value_count/t_dataset.shape[0]*interval_and_class_entropy\n",
        "      # print ('average_interval_and_class_entropy='+str(average_interval_and_class_entropy))\n",
        "    return average_interval_and_class_entropy\n",
        "\n",
        "\n",
        "  def calculate_probability_of_an_interval_and_class(self,t_dataset,class_label,min_value,max_value,attribute_no):    \n",
        "    interval_and_class_count = 0.0\n",
        "    for i in range(0, t_dataset.shape[0]):\n",
        "      #if (t_dataset.iat[i, attribute_no] != 'NaN'):      \n",
        "      if ((str(t_dataset.iat[i, t_dataset.shape[1]-1]) == str(class_label)) and (min_value <= t_dataset.iat[i, attribute_no]) and (max_value >= t_dataset.iat[i, attribute_no])):        \n",
        "        interval_and_class_count = interval_and_class_count+1\n",
        "    # print('interval_and_class_count =' + str(interval_and_class_count))   \n",
        "    interval_and_class_probability = interval_and_class_count/t_dataset.shape[0]\n",
        "    # print('interval_and_class_probability =' + str(interval_and_class_probability))\n",
        "    return interval_and_class_probability\n",
        "\n",
        "\n",
        "  def calculate_attribute_value_count(self,t_dataset,attribute_value,attribute_no):    \n",
        "    attribute_value_count=0\n",
        "    for i in range(0, t_dataset.shape[0]):\n",
        "      if (attribute_value == t_dataset.iat[i, attribute_no]):        \n",
        "        attribute_value_count = attribute_value_count+1\n",
        "    return attribute_value_count\n",
        "\n",
        "\n",
        "  def calculate_interval_value_count(self,t_dataset,min_value,max_value,attribute_no):    \n",
        "    interval_value_count=0\n",
        "    for i in range(0, t_dataset.shape[0]):\n",
        "      if ((min_value <= t_dataset.iat[i, attribute_no]) and (max_value >= t_dataset.iat[i, attribute_no])):        \n",
        "        interval_value_count = interval_value_count+1\n",
        "    return interval_value_count\n",
        "\n",
        "\n",
        "  def calculate_entropy_of_categorical_attribute(self,t_dataset,class_labels,attribute_no,no_of_classes,no_of_different_attribute_values,attribute_values):\n",
        "    average_attribute_and_class_entropy = 0.0\n",
        "    for i in range(0, no_of_different_attribute_values):\n",
        "      # print('i='+str(i))\n",
        "      attribute_and_class_entropy=0.0\n",
        "      for j in range(0, no_of_classes):\n",
        "        # print('j='+str(j))\n",
        "        attribute_and_class_probability = self.calculate_probability_of_an_attribute_and_class(t_dataset,class_labels[j],attribute_values[i],attribute_no)\n",
        "        if(attribute_and_class_probability>0.0):\n",
        "          attribute_and_class_entropy = attribute_and_class_entropy - attribute_and_class_probability*math.log2(attribute_and_class_probability)\n",
        "          # print ('attribute_and_class_entropy='+str(attribute_and_class_entropy))\n",
        "      attribute_value_count=self.calculate_attribute_value_count(t_dataset,attribute_values[i],attribute_no)\n",
        "      # print ('attribute_value_count='+str(attribute_value_count))\n",
        "      average_attribute_and_class_entropy = average_attribute_and_class_entropy + attribute_value_count/t_dataset.shape[0]*attribute_and_class_entropy\n",
        "      # print ('average_attribute_and_class_entropy='+str(average_attribute_and_class_entropy))\n",
        "    return average_attribute_and_class_entropy\n",
        "\n",
        "\n",
        "  def calculate_probability_of_an_attribute_and_class(self,t_dataset,class_label,attribute_value,attribute_no):    \n",
        "    attribute_and_class_count = 0.0\n",
        "    for i in range(0, t_dataset.shape[0]):\n",
        "      # if (t_dataset.iat[i, attribute_no] != 'NaN'):       \n",
        "      if ((str(t_dataset.iat[i, t_dataset.shape[1]-1]) == str(class_label)) and (attribute_value == t_dataset.iat[i, attribute_no])):        \n",
        "        attribute_and_class_count = attribute_and_class_count+1\n",
        "    # print('attribute_and_class_count =' + str(attribute_and_class_count))   \n",
        "    attribute_and_class_probability = attribute_and_class_count/t_dataset.shape[0]\n",
        "    # print('attribute_and_class_probability =' + str(attribute_and_class_probability))\n",
        "    return attribute_and_class_probability\n",
        "  \n",
        "  \n",
        "  \n",
        "  def find_information_gain(self,entropy_list,no_of_attributes):\n",
        "    information_gain_list = []\n",
        "    for i in range(0, 10):\n",
        "      information_gain_of_attributes = []\n",
        "      # print('i='+str(i))\n",
        "      for j in range(0, no_of_attributes-1):\n",
        "        # print('j='+str(j))\n",
        "        information_gain_of_attribute = entropy_list[i][no_of_attributes-1] - entropy_list[i][j]\n",
        "        information_gain_of_attributes.append(information_gain_of_attribute)\n",
        "      information_gain_list.append(information_gain_of_attributes)\n",
        "    return information_gain_list\n",
        "\n",
        "\n",
        "  def calculate_attribute_selection_probability(self,information_gain_list,no_of_attributes):\n",
        "    attribute_selection_probability_list = []\n",
        "    for i in range(0, 10):\n",
        "      probability_of_attributes_list = []\n",
        "      # print('i='+str(i))\n",
        "      sum_of_information_gain = 0\n",
        "      for j in range(0, no_of_attributes-1):\n",
        "        sum_of_information_gain = sum_of_information_gain + information_gain_list[i][j]\n",
        "      #print('sum_of_information_gain='+str(sum_of_information_gain))\n",
        "      for j in range(0, no_of_attributes-1):\n",
        "        # print('j='+str(j))\n",
        "        probability_of_attributes = information_gain_list[i][j]/sum_of_information_gain\n",
        "        probability_of_attributes_list.append(probability_of_attributes)        \n",
        "      attribute_selection_probability_list.append(probability_of_attributes_list)\n",
        "    return attribute_selection_probability_list\n",
        "\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X6XNMW8ndeq",
        "colab_type": "text"
      },
      "source": [
        "**P1_MOGA Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adqCZ5DXIFcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class P1_MOGA:\n",
        "  def __init__(self,experimental_dataset,fold_no,number_of_generation_of_BPMOGA,max_number_of_generation_of_P1MOGA,fraction_of_training_data,min_cross_prob_P1,max_cross_prob_P1,min_mu_prob_P1,max_mu_prob_P1):\n",
        "    print('Within P1_MOGA class')\n",
        "    self.pareto_population=initial_population\n",
        "    for generationP1 in range(0, max_number_of_generation_of_P1MOGA):\n",
        "    # for generationP1 in range(0, 4): # for testing\n",
        "      print('generationP1 ='+ str(generationP1))       \n",
        "      if(generationP1%2!=0):\n",
        "        builded_population=self.pareto_population        \n",
        "      elif(generationP1%2==0):\n",
        "        builded_population=Population()      \n",
        "        builded_population.set_values(fraction_of_training_data, experimental_dataset,fold_no)\n",
        "      crossover_probability=self.calculate_crossover_probability(generationP1,max_number_of_generation_of_P1MOGA,min_cross_prob_P1,max_cross_prob_P1)\n",
        "      # print('Population before crossover') # for testing\n",
        "      # builded_population.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_crossover=self.crossover(experimental_dataset,builded_population,crossover_probability)\n",
        "      # print('Population after crossover') # for testing\n",
        "      # population_after_crossover.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      mutation_probability=self.calculate_mutation_probability(generationP1,max_number_of_generation_of_P1MOGA,min_mu_prob_P1,max_mu_prob_P1)\n",
        "      # print('Population before mutation') # for testing\n",
        "      # builded_population.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_mutation=self.mutation(experimental_dataset,fold_no,builded_population,mutation_probability)\n",
        "      # print('Population after mutation') # for testing\n",
        "      # population_after_mutation.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_combination=self.combination(self.pareto_population,population_after_crossover,population_after_mutation)\n",
        "      # print('Population after combination') # for testing\n",
        "      # population_after_combination.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_eliminating_meaningless_condition=self.eliminate_meaningless_condition(experimental_dataset,fold_no,population_after_combination)\n",
        "      # print('Population after eliminating meaningless conditions') # for testing\n",
        "      # population_after_eliminating_meaningless_condition.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_eliminating_duplicate = self.eliminate_duplicate(population_after_eliminating_meaningless_condition)\n",
        "      # print('Population after eliminating duclicate') # for testing\n",
        "      # population_after_eliminating_duplicate.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_with_fitnesses = self.calculate_fitness(experimental_dataset,fold_no,population_after_eliminating_duplicate)      \n",
        "      # print('Population after fitness calculation') # for testing\n",
        "      # population_with_fitnesses.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      self.pareto_population = self.select_pareto_population(population_with_fitnesses)\n",
        "      # print('Population after Pareto Selection') # for testing\n",
        "      # self.pareto_population.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      if(self.pareto_population.size_of_population > 1000): #to limit population size of Phase1 to 1000\n",
        "        sorted_population=self.pareto_population.sortingCSRs()\n",
        "        top_1000_sorted_population= sorted_population.select_top_1000_chromosome()\n",
        "        self.pareto_population = top_1000_sorted_population\n",
        "        # print('Top 1000 chromosomes after Pareto Selection') # for testing\n",
        "        # pareto_population.show_population_with_fitness() # for testing\n",
        "        # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "\n",
        "  def select_pareto_population(self,population_with_fitnesses):    \n",
        "    pareto_population=population_with_fitnesses.select_pareto_population()\n",
        "    return pareto_population\n",
        "      \n",
        "\n",
        "  def calculate_fitness(self,experimental_dataset,fold_no,population_after_eliminating_duplicate):\n",
        "    for chromosome_no in range(0, population_after_eliminating_duplicate.size_of_population): \n",
        "      # print('chromosome_no='+str(chromosome_no))      \n",
        "      chromosome = population_after_eliminating_duplicate.chromosomes[chromosome_no]\n",
        "      if(str(chromosome.A) == str(np.nan)):\n",
        "        chromosome.calculate_fitness(experimental_dataset,fold_no)\n",
        "    return population_after_eliminating_duplicate\n",
        "\n",
        "\n",
        "  def eliminate_duplicate(self,population_after_eliminating_meaningless_condition):\n",
        "    flag_list =  [True for i in range(population_after_eliminating_meaningless_condition.size_of_population)]   \n",
        "    for outer_chromosome_no in range(0, population_after_eliminating_meaningless_condition.size_of_population):  \n",
        "      outer_chromosome = population_after_eliminating_meaningless_condition.chromosomes[outer_chromosome_no]\n",
        "      for inner_chromosome_no in range(outer_chromosome_no+1, population_after_eliminating_meaningless_condition.size_of_population): \n",
        "        inner_chromosome = population_after_eliminating_meaningless_condition.chromosomes[inner_chromosome_no]\n",
        "        if(outer_chromosome.check_equality(inner_chromosome)):          \n",
        "          flag_list[inner_chromosome_no] = False\n",
        "    list_of_chromosomes = []\n",
        "    for chromosome_no in range(0, population_after_eliminating_meaningless_condition.size_of_population):  \n",
        "      if(flag_list[chromosome_no]):\n",
        "        list_of_chromosomes.append(population_after_eliminating_meaningless_condition.chromosomes[chromosome_no])\n",
        "    population_after_eliminating_meaningless_condition = Population()\n",
        "    population_after_eliminating_meaningless_condition.set_values2(list_of_chromosomes)\n",
        "    return population_after_eliminating_meaningless_condition\n",
        "\n",
        "    \n",
        "\n",
        "  def eliminate_meaningless_condition(self,experimental_dataset,fold_no,population_after_combination):       \n",
        "    for chromosome_no in range(0, population_after_combination.size_of_population):\n",
        "    #for chromosome_no in range(0, 1):#for testing\n",
        "      dna_of_chromosome = population_after_combination.chromosomes[chromosome_no].dna_of_chromosome\n",
        "      # print(*dna_of_chromosome, sep = ',') # for testing\n",
        "      modified_dna_of_chromosome = []\n",
        "      for attribute_no in range(0, experimental_dataset.no_of_attributes-1):\n",
        "        # print('attribute_no='+str(attribute_no))#for testing\n",
        "        dna = []\n",
        "        gene_value = dna_of_chromosome[attribute_no]\n",
        "        # print('gene_value=')#for testing\n",
        "        # print(*gene_value, sep = ',')#for testing\n",
        "        if(experimental_dataset.types_of_attributes[attribute_no] == 'float64'):          \n",
        "          min_gene_value = gene_value[0]\n",
        "          #min_gene_value = 1.0\n",
        "          max_gene_value = gene_value[1]\n",
        "          # print('min_gene_value='+str(min_gene_value))#for testing\n",
        "          # print('max_gene_value='+str(max_gene_value))#for testing          \n",
        "          attribute_min_value = experimental_dataset.min_value_for_train_numerical_feature[fold_no][attribute_no]\n",
        "          #attribute_min_value = 1.0\n",
        "          attribute_max_value = experimental_dataset.max_value_for_train_numerical_feature[fold_no][attribute_no]\n",
        "          # print('attribute_min_value='+str(attribute_min_value))#for testing\n",
        "          # print('attribute_max_value='+str(attribute_max_value))#for testing\n",
        "          #if(str(min_gene_value) == str(np.nan)):#for testing          \n",
        "          #if(min_gene_value == attribute_min_value):          \n",
        "          if((min_gene_value == attribute_min_value) and (max_gene_value == attribute_max_value)):\n",
        "            dna.append(np.nan)\n",
        "            dna.append(np.nan)\n",
        "            # print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
        "            # print(*dna, sep = ',')#for testing\n",
        "            # print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
        "          elif(min_gene_value == attribute_min_value):\n",
        "            dna.append(np.nan)\n",
        "            dna.append(max_gene_value)\n",
        "            # print('BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB')\n",
        "            # print(*dna, sep = ',')#for testing\n",
        "            # print('BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB')\n",
        "          elif(max_gene_value == attribute_max_value):\n",
        "            dna.append(min_gene_value)\n",
        "            dna.append(np.nan)\n",
        "            # print('CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC')\n",
        "            # print(*dna, sep = ',')#for testing\n",
        "            # print('CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC')\n",
        "          else:\n",
        "            dna.append(min_gene_value)\n",
        "            dna.append(max_gene_value)\n",
        "            # print('DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD')\n",
        "            # print(*dna, sep = ',')#for testing\n",
        "            # print('DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD')\n",
        "        else: # for categorical attribute          \n",
        "          index_of_0 = gene_value.index(0) if 0 in gene_value else -1          \n",
        "          index_of_1 = gene_value.index(1) if 1 in gene_value else -1\n",
        "          if(index_of_0 == -1 or index_of_1 == -1):\n",
        "            dna.append(np.nan)\n",
        "            # print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
        "            # print(*dna, sep = ',')#for testing\n",
        "            # print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
        "          else:\n",
        "            dna.extend(gene_value)\n",
        "            # print('DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD')\n",
        "            # print(*dna, sep = ',')#for testing\n",
        "            # print('DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD')\n",
        "        modified_dna_of_chromosome.append(dna)\n",
        "      population_after_combination.chromosomes[chromosome_no].dna_of_chromosome = modified_dna_of_chromosome   \n",
        "    return population_after_combination\n",
        "\n",
        "\n",
        "  def combination(self,pareto_population,population_after_crossover,population_after_mutation):    \n",
        "    counter = 0\n",
        "    combined_list_chromosome = []\n",
        "    for chromosome_no in range(0, pareto_population.size_of_population):\n",
        "      combined_list_chromosome.append(pareto_population.chromosomes[chromosome_no])\n",
        "      counter = counter + 1\n",
        "    for chromosome_no in range(0, population_after_crossover.size_of_population):\n",
        "      combined_list_chromosome.append(population_after_crossover.chromosomes[chromosome_no])\n",
        "      counter = counter + 1\n",
        "    for chromosome_no in range(0, population_after_mutation.size_of_population):\n",
        "      combined_list_chromosome.append(population_after_mutation.chromosomes[chromosome_no])\n",
        "      counter = counter + 1\n",
        "    combined_population = Population()\n",
        "    combined_population.set_values2(combined_list_chromosome)\n",
        "    return combined_population\n",
        "\n",
        "\n",
        "  def calculate_mutation_probability(self,generationP1,max_number_of_generation_of_P1MOGA,min_mu_prob_P1,max_mu_prob_P1):\n",
        "    mutation_probability = (max_mu_prob_P1 - min_mu_prob_P1)*(max_number_of_generation_of_P1MOGA-1-generationP1)/(max_number_of_generation_of_P1MOGA-1)+min_mu_prob_P1\n",
        "    # print('mutation_probability='+str(mutation_probability))#for testing\n",
        "    return mutation_probability\n",
        "\n",
        "\n",
        "  def mutation(self,experimental_dataset,fold_no,population_before_mutation,mutation_probability):\n",
        "    number_of_mutation = (int)(population_before_mutation.size_of_population*mutation_probability)\n",
        "    # print(str(number_of_mutation))#for testing   \n",
        "    # print('mutation')#for testing\n",
        "    flag_list =  [True for i in range(population_before_mutation.size_of_population)] \n",
        "    list_of_dna_after_mutation = []\n",
        "    for mutation_counter in range(0, number_of_mutation): \n",
        "      random_number1 = random.randint(0,population_before_mutation.size_of_population-1)      \n",
        "      while(flag_list[random_number1]==False):\n",
        "        random_number1 = random.randint(0,population_before_mutation.size_of_population-1)\n",
        "      # print('random_number1='+str(random_number1)) #for testing\n",
        "      flag_list[random_number1] = False\n",
        "      mutation_counter = mutation_counter+1\n",
        "      attribute_no = random.randint(0,experimental_dataset.no_of_attributes-2)    \n",
        "      # attribute_no = 0   #for testing\n",
        "      # print('attribute_no='+str(attribute_no)) #for testing\n",
        "      gene_value_to_be_mutated = population_before_mutation.chromosomes[random_number1].dna_of_chromosome[attribute_no]      \n",
        "      dna_of_chromosome=population_before_mutation.chromosomes[random_number1].dna_of_chromosome\n",
        "      # print(*dna_of_chromosome, sep = ',') # for testing\n",
        "      left_dna = dna_of_chromosome[0:attribute_no]\n",
        "      right_dna = dna_of_chromosome[attribute_no+1:len(dna_of_chromosome)]\n",
        "      # print(*left_dna, sep = ',') # for testing\n",
        "      # print(*gene_value_to_be_mutated, sep = ',') # for testing\n",
        "      # print(*right_dna, sep = ',') # for testing\n",
        "      \n",
        "      if(experimental_dataset.types_of_attributes[attribute_no]=='float64'):\n",
        "        # print('float')\n",
        "        min_value = gene_value_to_be_mutated[0]\n",
        "        max_value = gene_value_to_be_mutated[1]\n",
        "        # print('min_value='+str(min_value)) #for testing\n",
        "        # print('max_value='+str(max_value)) #for testing\n",
        "        modified_index_min_value= -1\n",
        "        modified_index_max_value= -1     \n",
        "\n",
        "        if(str(min_value) != str(np.nan)):\n",
        "          index_of_min_value_in_change_point_index = experimental_dataset.change_points_of_train_data_set[fold_no][attribute_no].index(min_value) \n",
        "          # print('index_of_min_value_in_change_point_index='+str(index_of_min_value_in_change_point_index))\n",
        "          if(index_of_min_value_in_change_point_index==0):\n",
        "            modified_index_min_value= index_of_min_value_in_change_point_index+1\n",
        "          elif(index_of_min_value_in_change_point_index==len(experimental_dataset.change_points_of_train_data_set[fold_no][attribute_no]))-1:\n",
        "            modified_index_min_value= index_of_min_value_in_change_point_index-1\n",
        "          else:\n",
        "            random_number2 = random.uniform(0,1)\n",
        "            if(random_number2<0.5):\n",
        "              modified_index_min_value= index_of_min_value_in_change_point_index+1\n",
        "            else:\n",
        "              modified_index_min_value= index_of_min_value_in_change_point_index-1\n",
        "\n",
        "        if(str(max_value) != str(np.nan)):\n",
        "          index_of_max_value_in_change_point_index = experimental_dataset.change_points_of_train_data_set[fold_no][attribute_no].index(max_value) \n",
        "          # print('index_of_max_value_in_change_point_index='+str(index_of_max_value_in_change_point_index))\n",
        "          if(index_of_max_value_in_change_point_index==0):\n",
        "            modified_index_max_value= index_of_max_value_in_change_point_index+1\n",
        "          elif(index_of_max_value_in_change_point_index==len(experimental_dataset.change_points_of_train_data_set[fold_no][attribute_no]))-1:\n",
        "            modified_index_max_value= index_of_max_value_in_change_point_index-1\n",
        "          else:\n",
        "            random_number2 = random.uniform(0,1)\n",
        "            if(random_number2<0.5):\n",
        "              modified_index_max_value= index_of_max_value_in_change_point_index+1\n",
        "            else:\n",
        "              modified_index_max_value= index_of_max_value_in_change_point_index-1\n",
        "\n",
        "        modified_values = []\n",
        "        if(modified_index_min_value == -1):\n",
        "          modified_values.append(np.nan)\n",
        "        else:\n",
        "          modified_min_value = experimental_dataset.change_points_of_train_data_set[fold_no][attribute_no][modified_index_min_value]\n",
        "          # print('modified min value='+str(modified_min_value))\n",
        "          modified_values.append(modified_min_value)\n",
        "\n",
        "        if(modified_index_max_value == -1):\n",
        "          modified_values.append(np.nan)\n",
        "        else:          \n",
        "          modified_max_value = experimental_dataset.change_points_of_train_data_set[fold_no][attribute_no][modified_index_max_value]\n",
        "          # print('modified max value='+str(modified_max_value))\n",
        "          modified_values.append(modified_max_value)\n",
        "        \n",
        "        # print('modified value')\n",
        "        # print(*modified_values, sep = ',') # for testing            \n",
        "        \n",
        "        left_dna.append(modified_values)                \n",
        "        chield_dna = []\n",
        "        chield_dna.extend(left_dna)  \n",
        "        # print(*right_dna, sep = ',') # for testing  \n",
        "        if(attribute_no!=experimental_dataset.no_of_attributes-1):\n",
        "          chield_dna.extend(right_dna)\n",
        "        # print('chield_dna')\n",
        "        # print(*chield_dna, sep = ',') # for testing  \n",
        "\n",
        "      else: # for categorical attributes\n",
        "        # print('Object')\n",
        "        if(gene_value_to_be_mutated == np.nan):\n",
        "          modified_values = np.nan\n",
        "        else:\n",
        "          random_number3 = random.randint(0,len(gene_value_to_be_mutated)-1)\n",
        "          # print('random_number3='+str(random_number3))\n",
        "          left_part_of_gene_value =  gene_value_to_be_mutated[0:random_number3] \n",
        "          gene_value =  gene_value_to_be_mutated[random_number3]  \n",
        "          right_part_of_gene_value = gene_value_to_be_mutated[random_number3+1:len(gene_value_to_be_mutated)]\n",
        "          # print(*left_part_of_gene_value, sep = ',') # for testing\n",
        "          # print(gene_value) # for testing\n",
        "          # print(*right_part_of_gene_value, sep = ',') # for testing\n",
        "          if(gene_value == 0):\n",
        "            gene_value =1\n",
        "          else:\n",
        "            gene_value =0\n",
        "\n",
        "          if(random_number3!=0):\n",
        "            left_part_of_gene_value.append(gene_value)   \n",
        "          else:\n",
        "            left_part_of_gene_value=gene_value\n",
        "          modified_values = []  \n",
        "          if(left_part_of_gene_value==1 or left_part_of_gene_value==0):\n",
        "            modified_values.append(left_part_of_gene_value)\n",
        "          else:\n",
        "            modified_values.extend(left_part_of_gene_value)\n",
        "          if(random_number3!=len(gene_value_to_be_mutated)-1):\n",
        "            if(right_part_of_gene_value==1 or right_part_of_gene_value==0):\n",
        "              modified_values.append(right_part_of_gene_value)\n",
        "            else:\n",
        "              modified_values.extend(right_part_of_gene_value)            \n",
        "\n",
        "          # print('modified_values')  \n",
        "          # print(*modified_values, sep = ',') # for testing\n",
        "\n",
        "          left_dna.append(modified_values)                \n",
        "          chield_dna = []\n",
        "          chield_dna.extend(left_dna)  \n",
        "          # print(*right_dna, sep = ',') # for testing  \n",
        "          if(attribute_no!=experimental_dataset.no_of_attributes-1):\n",
        "            chield_dna.extend(right_dna)\n",
        "          # print('chield_dna')\n",
        "          # print(*chield_dna, sep = ',') # for testing            \n",
        "\n",
        "      list_of_dna_after_mutation.append(chield_dna)\n",
        "\n",
        "    population_after_mutation = Population()\n",
        "    population_after_mutation.set_values1(list_of_dna_after_mutation)\n",
        "    return population_after_mutation\n",
        "\n",
        "\n",
        "  def calculate_crossover_probability(self,generationP1,max_number_of_generation_of_P1MOGA,min_cross_prob_P1,max_cross_prob_P1):\n",
        "    crossover_probability = (max_cross_prob_P1 - min_cross_prob_P1)*generationP1/(max_number_of_generation_of_P1MOGA-1)+min_cross_prob_P1\n",
        "    # print('crossover_probability='+str(crossover_probability))#for testing\n",
        "    return crossover_probability\n",
        "\n",
        "\n",
        "  def crossover(self,experimental_dataset,population_before_crossover,crossover_probability):\n",
        "    # print('crossover')#for testing\n",
        "    number_of_crossover = (int)(population_before_crossover.size_of_population*crossover_probability)\n",
        "    # print(str(number_of_crossover))#for testing    \n",
        "    flag_list =  [True for i in range(population_before_crossover.size_of_population)] \n",
        "    # print(flag)#for testing\n",
        "    list_of_dna_after_crossover = []\n",
        "    for crossover_counter in range(0, number_of_crossover): # for testing\n",
        "      random_number1 = random.randint(0,population_before_crossover.size_of_population-1)\n",
        "      random_number2 = random.randint(0,population_before_crossover.size_of_population-1)      \n",
        "      while(random_number1==random_number2 or flag_list[random_number1]==False or flag_list[random_number2]==False):      \n",
        "        random_number1 = random.randint(0,population_before_crossover.size_of_population-1)\n",
        "        random_number2 = random.randint(0,population_before_crossover.size_of_population-1)   \n",
        "      #print('random_number1='+str(random_number1))#for testing\n",
        "      #print('random_number2='+str(random_number2))#for testing\n",
        "      dna_of_chromosome1=population_before_crossover.chromosomes[random_number1].dna_of_chromosome\n",
        "      dna_of_chromosome2=population_before_crossover.chromosomes[random_number2].dna_of_chromosome        \n",
        "      flag_list[random_number1]=False\n",
        "      flag_list[random_number2]=False\n",
        "      no_of_possible_crossover_points=len(dna_of_chromosome1)\n",
        "      # print('no_of_possible_crossover_points='+str(no_of_possible_crossover_points))#for testing\n",
        "      random_number3 = random.randint(1,no_of_possible_crossover_points)\n",
        "      # random_number3 = 24 #for testing\n",
        "      # print('random_number3='+str(random_number3))#for testing\n",
        "      left_dna1 = dna_of_chromosome1[0:random_number3-1]\n",
        "      middle_dna1 = dna_of_chromosome1[random_number3-1:random_number3]\n",
        "      right_dna1 = dna_of_chromosome1[random_number3:len(dna_of_chromosome1)]\n",
        "      # print(*dna_of_chromosome1, sep = ',') # for testing    \n",
        "      # print(*left_dna1, sep = ',') # for testing\n",
        "      # print(*middle_dna1, sep = ',') # for testing\n",
        "      # print(*right_dna1, sep = ',') # for testing\n",
        "      left_dna2 = dna_of_chromosome2[0:random_number3-1]\n",
        "      middle_dna2 = dna_of_chromosome2[random_number3-1:random_number3]\n",
        "      right_dna2 = dna_of_chromosome2[random_number3:len(dna_of_chromosome1)]\n",
        "      # print(*dna_of_chromosome2, sep = ',') # for testing\n",
        "      # print(*left_dna2, sep = ',') # for testing\n",
        "      # print(*middle_dna2, sep = ',') # for testing\n",
        "      # print(*right_dna2, sep = ',') # for testing\n",
        "      # print(experimental_dataset.types_of_attributes[random_number3-1])# for testing\n",
        "\n",
        "      if(experimental_dataset.types_of_attributes[random_number3-1]=='float64'):\n",
        "        left_of_middle_dna1 = middle_dna1[0][0:1]        \n",
        "        # print(*left_of_middle_dna1, sep = ',') # for testing\n",
        "        right_of_middle_dna1 = middle_dna1[0][1:2]\n",
        "        # print(*right_of_middle_dna1, sep = ',') # for testing\n",
        "        left_of_middle_dna2 = middle_dna2[0][0:1]\n",
        "        # print(*left_of_middle_dna2, sep = ',') # for testing\n",
        "        right_of_middle_dna2 = middle_dna2[0][1:2]\n",
        "        # print(*right_of_middle_dna2, sep = ',') # for testing \n",
        "        left_of_middle_dna1.extend(right_of_middle_dna2)       \n",
        "        middle_part1=left_of_middle_dna1\n",
        "        # print(middle_part1) # for testing        \n",
        "        left_of_middle_dna2.extend(right_of_middle_dna1)\n",
        "        middle_part2=left_of_middle_dna2\n",
        "        # print(middle_part2) # for testing        \n",
        "\n",
        "      else:#for categorical attribute\n",
        "        # print('object')# for testing\n",
        "        if(middle_dna1[0] == [np.nan] or middle_dna2[0] == [np.nan]):\n",
        "          middle_part1= middle_dna1[0]\n",
        "          middle_part2= middle_dna1[0]\n",
        "        else: \n",
        "          #print('*************************crossover******************************') \n",
        "          #print(middle_dna1[0]) # for testing     \n",
        "          random_number4 = random.randint(1,len(middle_dna1[0])-1)\n",
        "          # print('random_number4='+str(random_number4))#for testing\n",
        "          left_of_middle_dna1 = middle_dna1[0][0:random_number4]        \n",
        "          # print(*left_of_middle_dna1, sep = ',') # for testing\n",
        "          right_of_middle_dna1 = middle_dna1[0][random_number4:len(middle_dna1[0])]\n",
        "          # print(*right_of_middle_dna1, sep = ',') # for testing\n",
        "          left_of_middle_dna2 = middle_dna2[0][0:random_number4]\n",
        "          # print(*left_of_middle_dna2, sep = ',') # for testing\n",
        "          right_of_middle_dna2 = middle_dna2[0][random_number4:len(middle_dna1[0])]\n",
        "          # print(*right_of_middle_dna2, sep = ',') # for testing\n",
        "          left_of_middle_dna1.extend(right_of_middle_dna2)\n",
        "          middle_part1=left_of_middle_dna1\n",
        "          #print(middle_part1) # for testing        \n",
        "          left_of_middle_dna2.extend(right_of_middle_dna1)\n",
        "          middle_part2=left_of_middle_dna2\n",
        "          #print(middle_part2) # for testing   \n",
        "      \n",
        "      left_dna1.append(middle_part1)\n",
        "      chield_dna1 = []  \n",
        "      chield_dna1.extend(left_dna1)\n",
        "      if(random_number3!=experimental_dataset.no_of_attributes-1):\n",
        "        chield_dna1.extend(right_dna2)         \n",
        "      \n",
        "      left_dna2.append(middle_part2)           \n",
        "      chield_dna2 = []\n",
        "      chield_dna2.extend(left_dna2)   \n",
        "      if(random_number3!=experimental_dataset.no_of_attributes-1):\n",
        "        chield_dna2.extend(right_dna1)\n",
        "\n",
        "      list_of_dna_after_crossover.append(chield_dna1)\n",
        "      list_of_dna_after_crossover.append(chield_dna2)  \n",
        "\n",
        "    population_after_crossover = Population()\n",
        "    population_after_crossover.set_values1(list_of_dna_after_crossover)\n",
        "    return population_after_crossover\n",
        "        "
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmrCZJfmr3zF",
        "colab_type": "text"
      },
      "source": [
        "**Bi_Phased_MOGA Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XGjE1Ml96Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Bi_Phased_MOGA:  \n",
        "  def __init__(self,experimental_dataset,fold_no,initialPopulation,number_of_generation_of_BPMOGA,number_of_generation_of_P1MOGA,\n",
        "               number_of_generation_of_P2MOGA,size_of_initial_population_of_P2MOGA,fraction_of_training_data,min_cross_prob_P1,\n",
        "                max_cross_prob_P1,min_mu_prob_P1,max_mu_prob_P1,min_rule_prob_P2,max_rule_prob_P2,min_cross_prob_P2,\n",
        "                max_cross_prob_P2,min_mu_prob_P2,max_mu_prob_P2):    \n",
        "    print('Within Bi_Phased_MOGA class') # for testing\n",
        "    print('fold_no ='+ str(fold_no)) # for testing\n",
        "    population_from_earlier_gen_of_P2 = population_of_P2()\n",
        "    for counter in range(0, (int)(number_of_generation_of_BPMOGA/number_of_generation_of_P1MOGA)): \n",
        "    # for counter in range(0, 4): # for testing\n",
        "      print('counter ='+ str(counter))\n",
        "      P1MOGA = P1_MOGA(experimental_dataset,fold_no,number_of_generation_of_BPMOGA,number_of_generation_of_P1MOGA,\n",
        "               fraction_of_training_data,min_cross_prob_P1,max_cross_prob_P1,min_mu_prob_P1,max_mu_prob_P1)\n",
        "      # print('Population after one run of P1MOGA') # for testing\n",
        "      # P1MOGA.pareto_population.show_population_with_fitness() # for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing \n",
        "      P2MOGA = P2_MOGA(counter,experimental_dataset,fold_no,P1MOGA.pareto_population,number_of_generation_of_BPMOGA,number_of_generation_of_P2MOGA,\n",
        "               size_of_initial_population_of_P2MOGA,min_rule_prob_P2,max_rule_prob_P2,min_cross_prob_P2,max_cross_prob_P2,min_mu_prob_P2,max_mu_prob_P2) \n",
        "      if(counter == 0):\n",
        "        population_from_earlier_gen_of_P2 = P2MOGA.Pareto_population_of_P2 #??????????????????\n",
        "      #print('Population before combination from earlier generation of P2') # for testing  \n",
        "      #population_from_earlier_gen_of_P2.show_population_with_fitnesses()# for testing  \n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing      \n",
        "      #print('Population before combination from present generation of P2') # for testing  \n",
        "      #P2MOGA.Pareto_population_of_P2.show_population_with_fitnesses()# for testing  \n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing     \n",
        "      combined_population_after_P2 = P2MOGA.Pareto_population_of_P2.combine_population_P2(population_from_earlier_gen_of_P2)\n",
        "      #print('Population after combination') # for testing  \n",
        "      #combined_population_after_P2.show_population_with_fitnesses()# for testing  \n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing   \n",
        "      population_after_eliminating_duplicate_CR = self.eliminate_duplicate_CR(combined_population_after_P2) \n",
        "      #print('population_after_eliminating_duplicate') # for testing  \n",
        "      #population_after_eliminating_duplicate_CR.show_population_with_fitnesses()# for testing  \n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing   \n",
        "      population_after_pareto_selection = population_after_eliminating_duplicate_CR.pareto_selection_P2()\n",
        "      #print('population_after_pareto_selection') # for testing  \n",
        "      #population_after_pareto_selection.show_population_with_fitnesses() # for testing  \n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing \n",
        "      if(population_after_pareto_selection.size_of_population_of_P2 > 20):\n",
        "        sorted_population_of_P2 = population_after_pareto_selection.sortingCRs()        \n",
        "        top_20_sorted_population_of_P2 = sorted_population_of_P2.select_top_20_CRs()        \n",
        "        population_after_pareto_selection = top_20_sorted_population_of_P2\n",
        "      #print('top_20_sorted_population_of_P2') # for testing  \n",
        "      #population_after_pareto_selection.show_population_with_fitnesses() # for testing  \n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing \n",
        "      population_from_earlier_gen_of_P2 = population_after_pareto_selection\n",
        "      #print('population_from_earlier_gen_of_P2') # for testing  \n",
        "      #population_from_earlier_gen_of_P2.show_population_with_fitnesses() # for testing  \n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing \n",
        "      CSRs_from_CRs = self.take_CSRs_from_CRs(population_after_pareto_selection)\n",
        "      # print('CSRs_from_CRs') # for testing \n",
        "      # CSRs_from_CRs.show_population_with_fitness()\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing  \n",
        "      pareto_CSRs_from_CRs = CSRs_from_CRs.select_pareto_population()\n",
        "      # print('Pareto CSRs_from_CRs') # for testing \n",
        "      # pareto_CSRs_from_CRs.show_population_with_fitness()\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing \n",
        "      initialPopulation = pareto_CSRs_from_CRs\n",
        "      # to check the convergence of BPMOGA\n",
        "      print('Maximum total confidence =' + str(population_after_pareto_selection.find_max_Total_confidence())) # for testing   \n",
        "      print('Maximum total coverage =' + str(population_after_pareto_selection.find_max_Total_coverage())) # for testing   \n",
        "      print('Minimum number of CSRs =' + str(population_after_pareto_selection.find_min_CSRs())) # for testing   \n",
        "    \n",
        "    self.CRs_of_BPMOGA = population_after_pareto_selection\n",
        "    \n",
        "\n",
        "      \n",
        "\n",
        "  def take_CSRs_from_CRs(self,population_after_pareto_selection):   \n",
        "    list_of_CSRs = []\n",
        "    for CR_no in range(0, population_after_pareto_selection.size_of_population_of_P2):\n",
        "      CR = population_after_pareto_selection.chromosomes_of_P2[CR_no]      \n",
        "      for CSR_no in range(0, len(CR.dna_of_P2)):\n",
        "        Flag = True\n",
        "        if(CR.dna_of_P2[CSR_no] == 1):\n",
        "          for selected_CSR_no in range(0, len(list_of_CSRs)):\n",
        "            if(CR.sorted_population_from_P1_MOGA.chromosomes[CSR_no].check_equality(list_of_CSRs[selected_CSR_no]) == True):\n",
        "              Flag = False\n",
        "              break\n",
        "          if(Flag == True):\n",
        "            list_of_CSRs.append(CR.sorted_population_from_P1_MOGA.chromosomes[CSR_no])\n",
        "    P1_population_after_P2 = Population()\n",
        "    P1_population_after_P2.set_values2(list_of_CSRs)\n",
        "    return P1_population_after_P2  \n",
        "\n",
        "    \n",
        "\n",
        "  def eliminate_duplicate_CR(self,combined_population_after_P2):\n",
        "    #print('Size of population='+str(combined_population_after_P2.size_of_population_of_P2)) # for testing  \n",
        "    size_of_population = combined_population_after_P2.size_of_population_of_P2\n",
        "    flag_list =  [True for i in range(0,size_of_population)] \n",
        "    flag_list[0] = False\n",
        "    for outer_loop in range(0, size_of_population):\n",
        "      if(flag_list[outer_loop] == True):\n",
        "        CR1 = combined_population_after_P2.chromosomes_of_P2[outer_loop]\n",
        "        for inner_loop in range(outer_loop+1, size_of_population):\n",
        "          if(flag_list[inner_loop] == True):\n",
        "            CR2 = combined_population_after_P2.chromosomes_of_P2[inner_loop]\n",
        "            if(len(CR1.dna_of_P2) == len(CR2.dna_of_P2)):\n",
        "              if(str(CR1.dna_of_P2) == str(CR2.dna_of_P2)):\n",
        "                for CSR in range(0, len(CR1.dna_of_P2)):\n",
        "                  if(CR1.dna_of_P2[CSR] == 1):\n",
        "                    if(str(CR1.sorted_population_from_P1_MOGA.chromosomes[CSR].dna_of_chromosome) == str(CR2.sorted_population_from_P1_MOGA.chromosomes[CSR].dna_of_chromosome)):\n",
        "                      pass\n",
        "                    else:\n",
        "                      flag_list[inner_loop] = False\n",
        "              else:\n",
        "                flag_list[inner_loop] = False\n",
        "            else:\n",
        "              flag_list[inner_loop] = False\n",
        "    #print(*flag_list, sep = ',') # for testing\n",
        "    list_of_CRs = []\n",
        "    modified_size_of_population = 0\n",
        "    for CR_no in range(0, size_of_population):\n",
        "      if(flag_list[CR_no] == False):\n",
        "        list_of_CRs.append(combined_population_after_P2.chromosomes_of_P2[CR_no])\n",
        "        modified_size_of_population = modified_size_of_population + 1\n",
        "    population_after_eliminating_duplicate_CR = population_of_P2()    \n",
        "    population_after_eliminating_duplicate_CR.set_values3(modified_size_of_population,list_of_CRs)\n",
        "    return population_after_eliminating_duplicate_CR\n",
        "\n",
        "    "
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLVfVZTvsE-R",
        "colab_type": "text"
      },
      "source": [
        "**Population Class**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq-aX5Mi79v6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Population: \n",
        "  def __init__(self): pass       \n",
        "  \n",
        "  def set_values(self,fraction_of_training_data,experimental_dataset,fold_no):\n",
        "    self.size_of_population = self.decide_size_of_population(fraction_of_training_data,experimental_dataset.train_list_with_NaN[fold_no])\n",
        "    # self.show_population_size()# for testing\n",
        "    self.chromosomes  = self.create_population(self.size_of_population,experimental_dataset,fold_no)\n",
        "\n",
        "\n",
        "  def set_values1(self,list_of_dna): \n",
        "    self.size_of_population = len(list_of_dna)\n",
        "    # self.show_population_size()# for testing\n",
        "    self.chromosomes  = self.create_population1(self.size_of_population,list_of_dna)\n",
        "\n",
        "\n",
        "  def set_values2(self,list_of_chromsomes):\n",
        "    self.size_of_population = len(list_of_chromsomes)\n",
        "    self.chromosomes = list_of_chromsomes\n",
        "\n",
        "  \n",
        "  def decide_size_of_population(self,fraction_of_training_data,train_dataset):\n",
        "    size_of_population = int(fraction_of_training_data * train_dataset.shape[0])\n",
        "    # print('Size of population='+str(size_of_population))\n",
        "    if (size_of_population<20):\n",
        "      size_of_population = 20 #for testing\n",
        "    return size_of_population\n",
        "\n",
        "\n",
        "  def show_population_size(self):\n",
        "    print('Size of population='+str(self.size_of_population))\n",
        "\n",
        "\n",
        "  def show_population(self):\n",
        "    self.show_population_size()    \n",
        "    for i in range(0, self.size_of_population):\n",
        "      self.chromosomes[i].show_chromosome()\n",
        "\n",
        "\n",
        "  def show_population_with_fitness(self):\n",
        "    self.show_population_size()    \n",
        "    for i in range(0, self.size_of_population):\n",
        "      self.chromosomes[i].show_chromosome_with_fitness()\n",
        "\n",
        "\n",
        "  def create_population(self,size_of_population,experimental_dataset,fold_no):   \n",
        "    no_of_chromosome = 0\n",
        "    chromosomes = []\n",
        "    while (no_of_chromosome < size_of_population):\n",
        "    #for i in range(0, size_of_population-1):    \n",
        "      random_number1 = random.randint(1,experimental_dataset.no_of_records_in_train_list[fold_no]-1)\n",
        "      random_number2 = random.randint(1,experimental_dataset.no_of_records_in_train_list[fold_no]-1)\n",
        "      # random_number1 = 40 # for testing\n",
        "      # random_number2 = 58 # for testing      \n",
        "      # random_number1 = 28 # for testing\n",
        "      # random_number2 = 158 # for testing   \n",
        "      # random_number1 = 104 # for testing\n",
        "      # random_number2 = 105 # for testing   \n",
        "      # print(experimental_dataset.no_of_attributes) # for testing\n",
        "      class_label1 = experimental_dataset.train_list_with_NaN[fold_no].iat[random_number1, experimental_dataset.no_of_attributes-1]\n",
        "      class_label2 = experimental_dataset.train_list_with_NaN[fold_no].iat[random_number2, experimental_dataset.no_of_attributes-1]\n",
        "      # print(class_label1)# for testing\n",
        "      # print(class_label2)# for testing\n",
        "      if(class_label1 == class_label2):\n",
        "        # print('class labels are equal')# for testing        \n",
        "        chromosome = Chromosome()\n",
        "        chromosome.set_values(experimental_dataset,fold_no,random_number1,random_number2)\n",
        "        chromosomes.append(chromosome)\n",
        "        no_of_chromosome =no_of_chromosome+1\n",
        "    return chromosomes\n",
        "\n",
        "    \n",
        "  def create_population1(self,size_of_population,list_of_dna):   \n",
        "    no_of_chromosome = 0\n",
        "    chromosomes = []\n",
        "    while (no_of_chromosome<size_of_population):\n",
        "      chromosome = Chromosome()\n",
        "      chromosome.set_values1(list_of_dna[no_of_chromosome])\n",
        "      chromosomes.append(chromosome)\n",
        "      no_of_chromosome=no_of_chromosome+1\n",
        "    return chromosomes\n",
        "\n",
        "\n",
        "  def select_pareto_population(self):\n",
        "    flag_list =  [True for i in range(0,self.size_of_population)] \n",
        "    for outer_loop in range(0, self.size_of_population):\n",
        "      CL1 = self.chromosomes[outer_loop].class_label_of_chromosome\n",
        "      Con1 = self.chromosomes[outer_loop].Confidence\n",
        "      Cov1 = self.chromosomes[outer_loop].Coverage\n",
        "      NVA1 = self.chromosomes[outer_loop].no_of_valid_attributes\n",
        "      for inner_loop in range(0, self.size_of_population):\n",
        "        CL2 = self.chromosomes[inner_loop].class_label_of_chromosome\n",
        "        Con2 = self.chromosomes[inner_loop].Confidence\n",
        "        Cov2 = self.chromosomes[inner_loop].Coverage\n",
        "        NVA2 = self.chromosomes[inner_loop].no_of_valid_attributes\n",
        "        if((CL1 == CL2) and (outer_loop != inner_loop)):\n",
        "          if(((Con1>Con2) and (Cov1>Cov2) and (NVA1<NVA2)) \n",
        "            or ((Con1>Con2) and (Cov1>Cov2) and (NVA1==NVA2)) \n",
        "            or ((Con1>Con2) and (Cov1==Cov2) and (NVA1<NVA2)) \n",
        "            or ((Con1==Con2) and (Cov1>Cov2) and (NVA1<NVA2)) \n",
        "            or ((Con1>Con2) and (Cov1==Cov2) and (NVA1==NVA2)) \n",
        "            or ((Con1==Con2) and (Cov1>Cov2) and (NVA1==NVA2)) \n",
        "            or ((Con1==Con2) and (Cov1==Cov2) and (NVA1<NVA2))):\n",
        "            flag_list[inner_loop] = False  \n",
        "            break\n",
        "    pareto_population = Population() \n",
        "    list_of_chromsomes = []       \n",
        "    for counter in range(0, self.size_of_population):\n",
        "      if(flag_list[counter] == True):\n",
        "        list_of_chromsomes.append(self.chromosomes[counter])\n",
        "    pareto_population.set_values2(list_of_chromsomes)\n",
        "    return pareto_population    \n",
        "\n",
        "\n",
        "\n",
        "  def sortingCSRs(self): \n",
        "    flag_list =  [True for i in range(0, self.size_of_population)]   \n",
        "    counter=0\n",
        "    Chromosome_list = []\n",
        "    for loop_counter in range(0, self.size_of_population): \n",
        "      con = 0\n",
        "      cov = 0\n",
        "      NOVA = 10000\n",
        "      chromosome_number=-1\n",
        "      for chromosome_no in range(0, self.size_of_population): \n",
        "        if(flag_list[chromosome_no] == True):\n",
        "          if(con < self.chromosomes[chromosome_no].Confidence ):\n",
        "            chromosome_number=chromosome_no\n",
        "            con = self.chromosomes[chromosome_no].Confidence\n",
        "            cov = self.chromosomes[chromosome_no].Coverage\n",
        "            NOVA = self.chromosomes[chromosome_no].no_of_valid_attributes\n",
        "          elif(con == self.chromosomes[chromosome_no].Confidence ):\n",
        "            if(cov < self.chromosomes[chromosome_no].Coverage):\n",
        "              chromosome_number=chromosome_no\n",
        "              cov = self.chromosomes[chromosome_no].Coverage\n",
        "              NOVA = self.chromosomes[chromosome_no].no_of_valid_attributes\n",
        "            elif(cov == self.chromosomes[chromosome_no].Coverage):\n",
        "              if(NOVA > self.chromosomes[chromosome_no].no_of_valid_attributes):\n",
        "                chromosome_number=chromosome_no\n",
        "                NOVA = self.chromosomes[chromosome_no].no_of_valid_attributes\n",
        "              elif(NOVA == self.chromosomes[chromosome_no].no_of_valid_attributes):\n",
        "                chromosome_number=chromosome_no\n",
        "      flag_list [chromosome_number] = False\n",
        "      Chromosome_list.append(self.chromosomes[chromosome_number])\n",
        "      counter= counter+1\n",
        "    sorted_population = Population()\n",
        "    sorted_population.set_values2(Chromosome_list)\n",
        "    return sorted_population\n",
        "\n",
        "\n",
        "  def select_top_1000_chromosome(self): \n",
        "    top_1000_chromosomes = self.chromosomes[:1000]\n",
        "    sorted_population = Population()\n",
        "    sorted_population.set_values2(top_1000_chromosomes)\n",
        "    return sorted_population\n",
        "\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJJm0f6lsPyx",
        "colab_type": "text"
      },
      "source": [
        "**Chromosome Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw2JjLMTJDtc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Chromosome:\n",
        "  \n",
        "  def __init__(self): \n",
        "    pass\n",
        "\n",
        "  def set_values(self,experimental_dataset,fold_no,random_number1,random_number2):\n",
        "    self.dna_of_chromosome = self.create_chromosome(experimental_dataset,fold_no,random_number1,random_number2)\n",
        "    # self.show_chromosome() # for testing\n",
        "    self.A = np.nan\n",
        "    self.C = np.nan\n",
        "    self.AUC = np.nan\n",
        "    self.Confidence = np.nan\n",
        "    self.Coverage = np.nan\n",
        "    self.no_of_valid_attributes = np.nan\n",
        "    self.list_of_records_covered = []\n",
        "    self.class_label_of_chromosome = np.nan\n",
        "\n",
        "\n",
        "  def set_values1(self,dna_of_chromosome):\n",
        "    self.dna_of_chromosome = dna_of_chromosome\n",
        "    # self.show_chromosome () # for testing \n",
        "    self.A = np.nan\n",
        "    self.C = np.nan\n",
        "    self.AUC = np.nan\n",
        "    self.Confidence = np.nan\n",
        "    self.Coverage = np.nan\n",
        "    self.no_of_valid_attributes = np.nan\n",
        "    self.list_of_records_covered = []\n",
        "    self.class_label_of_chromosome = np.nan\n",
        "  \n",
        "\n",
        "  def check_equality(self,chromosome):\n",
        "    chromosome1 = self\n",
        "    chromosome2 = chromosome\n",
        "    for attribute_number in range(0, len(chromosome1.dna_of_chromosome)):\n",
        "      dna_value1 = chromosome1.dna_of_chromosome[attribute_number]\n",
        "      dna_value2 = chromosome2.dna_of_chromosome[attribute_number]\n",
        "      if(dna_value1 != dna_value2):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  def calculate_fitness(self,experimental_dataset,fold_no):\n",
        "    #self.show_chromosome() #for testing    \n",
        "    chromosome = self\n",
        "    self.A = 0\n",
        "    self.C = 0\n",
        "    self.AUC = 0\n",
        "    self.Confidence = 0\n",
        "    self.Coverage = 0\n",
        "    self.no_of_valid_attributes = 0\n",
        "    self.list_of_records_covered = []\n",
        "    self.class_label_of_chromosome = np.nan\n",
        "    class_label_counter = []\n",
        "    # print(experimental_dataset.no_of_classes[fold_no]) #for testing\n",
        "    for class_no in range(0, experimental_dataset.no_of_classes[fold_no]):\n",
        "      class_label_counter.append(0)\n",
        "    # print(experimental_dataset.no_of_records_in_train_list[fold_no]) #for testing     \n",
        "\n",
        "    for record_no in range(0, experimental_dataset.no_of_records_in_train_list[fold_no]):\n",
        "      # print('record_no = ' +str(record_no)) #for testing\n",
        "      flag = self.check_coverage_of_a_record_by_a_chromosome(experimental_dataset,fold_no,record_no)\n",
        "      # print('Chromosome coverage flag = ' +str(flag))#for testing\n",
        "      if(flag==True):\n",
        "        self.A = self.A + 1\n",
        "        self.list_of_records_covered.append(record_no)\n",
        "        class_label = experimental_dataset.train_list_with_NaN[fold_no].iat[record_no,experimental_dataset.no_of_attributes-1]\n",
        "        # print('class_label = ' +str(class_label)) #for testing \n",
        "        for loop_counter in range(0, experimental_dataset.no_of_classes[fold_no]):\n",
        "          if(str(class_label) == str(experimental_dataset.class_labels[fold_no][loop_counter])):            \n",
        "            class_label_counter[loop_counter] = class_label_counter[loop_counter] + 1    \n",
        "    # print('A ='+str(self.A)) \n",
        "\n",
        "    # for loop_counter in range(0, experimental_dataset.no_of_classes[fold_no]):\n",
        "      # print('class_label_counter[loop_counter] = ' +str(class_label_counter[loop_counter])) #for testing       \n",
        "    max_class_label_counter = max(class_label_counter)  \n",
        "    # print('max_class_label_counter = ' +str(max_class_label_counter)) \n",
        "    index_of_max_label = class_label_counter.index(max_class_label_counter)\n",
        "    # print('index_of_max_label = ' +str(index_of_max_label)) \n",
        "    chosen_class_label = experimental_dataset.class_labels[fold_no][index_of_max_label]\n",
        "    # print('chosen_class_label = ' +str(chosen_class_label))\n",
        "    self.class_label_of_chromosome = chosen_class_label\n",
        "    # print(*self.list_of_records_covered, sep =',') # for testing\n",
        "\n",
        "    for record_no in range(0, experimental_dataset.no_of_records_in_train_list[fold_no]):\n",
        "      # print('record_no = ' +str(record_no)) #for testing\n",
        "      flag = self.check_coverage_of_a_record_by_a_chromosome(experimental_dataset,fold_no,record_no)\n",
        "      #if(record_no in self.list_of_records_covered):\n",
        "        #flag = True\n",
        "      # print('Chromosome coverage flag = ' +str(flag))#for testing\n",
        "      if(flag==True):\n",
        "        if(str(chosen_class_label) == str(experimental_dataset.train_list_with_NaN[fold_no].iat[record_no,experimental_dataset.no_of_attributes-1])):\n",
        "          self.AUC = self.AUC+1  \n",
        "      if(str(chosen_class_label) == str(experimental_dataset.train_list_with_NaN[fold_no].iat[record_no,experimental_dataset.no_of_attributes-1])):\n",
        "        self.C = self.C+1\n",
        "    # print('AUC ='+str(self.AUC)) \n",
        "    # print('C ='+str(self.C)) \n",
        "\n",
        "    if((self.A !=0) and (self.AUC !=0)):\n",
        "      self.Confidence =  self.AUC/self.A\n",
        "      self.Coverage =  self.AUC/self.C\n",
        "\n",
        "    #print('Confidence ='+str(self.Confidence)) \n",
        "    #print('Coverage ='+str(self.Coverage)) \n",
        "\n",
        "    for attribute_number in range(0, experimental_dataset.no_of_attributes-1):\n",
        "      gene_value = self.dna_of_chromosome[attribute_number]\n",
        "      # print('attribute_number ='+str(attribute_number))\n",
        "      if(experimental_dataset.types_of_attributes[attribute_number] == 'float64'):      \n",
        "        min_value = gene_value[0]\n",
        "        max_value = gene_value[1]\n",
        "        if((str(min_value) == str(np.nan)) and (str(max_value) == str(np.nan))):\n",
        "          pass\n",
        "          # print('InValid')\n",
        "        else:\n",
        "          self.no_of_valid_attributes = self.no_of_valid_attributes+1\n",
        "          # print('Valid')\n",
        "      else:\n",
        "        if(str(gene_value[0]) == str(np.nan)):\n",
        "          pass\n",
        "          # print('InValid')\n",
        "        else:\n",
        "          self.no_of_valid_attributes = self.no_of_valid_attributes+1\n",
        "          # print('Valid')\n",
        "\n",
        "    #print('no_of_valid_attributes ='+str(self.no_of_valid_attributes))  \n",
        "\n",
        "    #self.show_chromosome_with_fitness()   \n",
        "\n",
        "\n",
        "  def check_coverage_of_a_record_by_a_chromosome(self,experimental_dataset,fold_no,record_no):    \n",
        "    for attribute_no in range(0, experimental_dataset.no_of_attributes-1):\n",
        "      # print('attribute_no = ' +str(attribute_no)) #for testing\n",
        "      flag1 = self.check_coverage_of_an_attribute_by_a_gene(experimental_dataset,fold_no,record_no,attribute_no)\n",
        "      # print('Gene coverage flag = ' +str(flag1))\n",
        "      if(flag1==False):\n",
        "        return False      \n",
        "    return True\n",
        "\n",
        "  def check_coverage_of_a_test_record_by_a_chromosome(self,experimental_dataset,fold_no,record_no):  \n",
        "    for attribute_no in range(0, experimental_dataset.no_of_attributes-1):\n",
        "      # print('attribute_no = ' +str(attribute_no)) #for testing\n",
        "      flag1 = self.check_coverage_of_a_test_attribute_by_a_gene(experimental_dataset,fold_no,record_no,attribute_no)\n",
        "      # print('Gene coverage flag = ' +str(flag1))\n",
        "      if(flag1==False):\n",
        "        return False      \n",
        "    return True\n",
        "\n",
        "\n",
        "  def check_coverage_of_an_attribute_by_a_gene(self,experimental_dataset,fold_no,record_no,attribute_number): \n",
        "    attribute_value = experimental_dataset.train_list_with_NaN[fold_no].iat[record_no,attribute_number]\n",
        "    # print('attribute_value = ' +str(attribute_value)) \n",
        "    if(str(attribute_value) == str(np.nan)):\n",
        "      return True\n",
        "    gene_value = self.dna_of_chromosome[attribute_number]\n",
        "    # print(*gene_value, sep = \",\")\n",
        "    if(experimental_dataset.types_of_attributes[attribute_number] == 'float64'):      \n",
        "      min_value = gene_value[0]\n",
        "      max_value = gene_value[1]\n",
        "      # print('min_value = ' +str(min_value))\n",
        "      # print('max_value = ' +str(max_value))           \n",
        "      if((str(min_value) == str(np.nan)) and (str(max_value) == str(np.nan))):\n",
        "        # print('A') # for testing\n",
        "        return True\n",
        "      elif((str(min_value) != str(np.nan)) and (str(max_value) == str(np.nan))):\n",
        "        if(min_value<=attribute_value):\n",
        "          # print('B') # for testing\n",
        "          return True\n",
        "        else:\n",
        "          # print('C') # for testing\n",
        "          return False\n",
        "      elif((str(min_value) == str(np.nan)) and (str(max_value) != str(np.nan))):   \n",
        "        if(max_value>=attribute_value):\n",
        "          # print('D') # for testing\n",
        "          return True\n",
        "        else:\n",
        "          # print('E') # for testing\n",
        "          return False\n",
        "      elif((str(min_value) != str(np.nan)) and (str(max_value) != str(np.nan))):   \n",
        "        if((min_value<=attribute_value) and (max_value>=attribute_value)):\n",
        "          # print('F') # for testing\n",
        "          return True\n",
        "        else:\n",
        "          # print('G') # for testing\n",
        "          return False\n",
        "\n",
        "    else:# for categorical attributes      \n",
        "      if(str(gene_value[0]) == str(np.nan)):\n",
        "        return True\n",
        "      else:\n",
        "        index_of_attribute_value = -1\n",
        "        # print('no_of_different_attribute_values= ' +str(experimental_dataset.no_of_different_attribute_values[fold_no][attribute_number]))\n",
        "        for index_no in range(0, experimental_dataset.no_of_different_attribute_values[fold_no][attribute_number]):\n",
        "          if(str(experimental_dataset.sorted_unique_attribute_values_of_train_dataset[fold_no][attribute_number][index_no]) == str(attribute_value)):\n",
        "            index_of_attribute_value = index_no\n",
        "            break\n",
        "        # print(*gene_value, sep = \",\")\n",
        "        # print('str(attribute_value) = ' +str(attribute_value))  \n",
        "        # print('index_of_attribute_value = ' +str(index_of_attribute_value)) \n",
        "        # print('gene_value[index_of_attribute_value] = ' +str(gene_value[index_of_attribute_value])) \n",
        "        if(gene_value[index_of_attribute_value]==1):\n",
        "          return True\n",
        "        else:\n",
        "          return False\n",
        "\n",
        "  def check_coverage_of_a_test_attribute_by_a_gene(self,experimental_dataset,fold_no,record_no,attribute_number): \n",
        "    attribute_value = experimental_dataset.test_list_with_NaN[fold_no].iat[record_no,attribute_number]\n",
        "    # print('attribute_value = ' +str(attribute_value)) \n",
        "    if(str(attribute_value) == str(np.nan)):\n",
        "      return True\n",
        "    gene_value = self.dna_of_chromosome[attribute_number]\n",
        "    # print(*gene_value, sep = \",\")\n",
        "    if(experimental_dataset.types_of_attributes[attribute_number] == 'float64'):      \n",
        "      min_value = gene_value[0]\n",
        "      max_value = gene_value[1]\n",
        "      # print('min_value = ' +str(min_value))\n",
        "      # print('max_value = ' +str(max_value))           \n",
        "      if((str(min_value) == str(np.nan)) and (str(max_value) == str(np.nan))):\n",
        "        # print('A') # for testing\n",
        "        return True\n",
        "      elif((str(min_value) != str(np.nan)) and (str(max_value) == str(np.nan))):\n",
        "        if(min_value<=attribute_value):\n",
        "          # print('B') # for testing\n",
        "          return True\n",
        "        else:\n",
        "          # print('C') # for testing\n",
        "          return False\n",
        "      elif((str(min_value) == str(np.nan)) and (str(max_value) != str(np.nan))):   \n",
        "        if(max_value>=attribute_value):\n",
        "          # print('D') # for testing\n",
        "          return True\n",
        "        else:\n",
        "          # print('E') # for testing\n",
        "          return False\n",
        "      elif((str(min_value) != str(np.nan)) and (str(max_value) != str(np.nan))):   \n",
        "        if((min_value<=attribute_value) and (max_value>=attribute_value)):\n",
        "          # print('F') # for testing\n",
        "          return True\n",
        "        else:\n",
        "          # print('G') # for testing\n",
        "          return False\n",
        "          \n",
        "          \n",
        "  def create_chromosome(self,experimental_dataset,fold_no,random_number1,random_number2): \n",
        "    dna_of_chromosome = []  \n",
        "    # print('Record Number 1 =' + str(random_number1))# for testing \n",
        "    # print(experimental_dataset.train_list_with_NaN[fold_no].loc[random_number1,:])    \n",
        "    # print('Record Number 2 =' + str(random_number2))# for testing \n",
        "    # print(experimental_dataset.train_list_with_NaN[fold_no].loc[random_number2,:])     \n",
        "    for attribute_number in range(0, experimental_dataset.no_of_attributes-1):\n",
        "      # print('attribute_number='+str(attribute_number))# for testing\n",
        "      # print('experimental_dataset.types_of_attributes[attribute_number]='+str(experimental_dataset.types_of_attributes[attribute_number]))# for testing  \n",
        "      if(experimental_dataset.types_of_attributes[attribute_number] == 'float64'):\n",
        "        random_number5 = random.uniform(0, 1)\n",
        "        if(random_number5>experimental_dataset.attribute_selection_probability_list[fold_no][attribute_number]):\n",
        "          modified_attribute_value1 = np.nan\n",
        "          modified_attribute_value2 = np.nan\n",
        "        else:\n",
        "          attribute_value1 = experimental_dataset.train_list_with_NaN[fold_no].iat[random_number1,attribute_number]\n",
        "          attribute_value2 = experimental_dataset.train_list_with_NaN[fold_no].iat[random_number2,attribute_number]\n",
        "          # print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')# for testing \n",
        "          # print('attribute_value1='+str(attribute_value1))# for testing     \n",
        "          # print('attribute_value2='+str(attribute_value2))# for testing \n",
        "          # print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')# for testing \n",
        "          if(str(attribute_value1) == str(np.nan) and str(attribute_value2) != str(np.nan)):\n",
        "            modified_attribute_value1 = np.nan\n",
        "            modified_attribute_value2 = attribute_value2\n",
        "          elif(str(attribute_value1) != str(np.nan) and str(attribute_value2) == str(np.nan)): \n",
        "            modified_attribute_value1 = attribute_value1\n",
        "            modified_attribute_value2 = np.nan\n",
        "          elif(str(attribute_value1) == str(np.nan) and str(attribute_value2) == str(np.nan)):\n",
        "            modified_attribute_value1 = np.nan\n",
        "            modified_attribute_value2 = np.nan  \n",
        "          else:              \n",
        "            if(attribute_value1>attribute_value2):\n",
        "              modified_attribute_value1 = attribute_value2\n",
        "              modified_attribute_value2 = attribute_value1\n",
        "            else:\n",
        "              modified_attribute_value1 = attribute_value1\n",
        "              modified_attribute_value2 = attribute_value2              \n",
        "            random_number3 = random.uniform(0, 1)\n",
        "            if(random_number3 < 0.5):\n",
        "              random_number4 = random.uniform(0, 1)\n",
        "              if(random_number4 < 0.5):\n",
        "                modified_attribute_value1 = np.nan\n",
        "              else:\n",
        "                modified_attribute_value2 = np.nan          \n",
        "          # print('BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB')# for testing \n",
        "          # print('modified_attribute_value1='+str(modified_attribute_value1))# for testing     \n",
        "          # print('modified_attribute_value2='+str(modified_attribute_value2))# for testing \n",
        "          # print('BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB')# for testing \n",
        "          if(str(modified_attribute_value1) == str(experimental_dataset.change_points_of_train_data_set[fold_no][attribute_number][0])):\n",
        "            pass\n",
        "          elif(str(modified_attribute_value1) != str(np.nan)):\n",
        "            counter1 = -1\n",
        "            no_of_change_points = len(experimental_dataset.change_points_of_train_data_set[fold_no][attribute_number])\n",
        "            for i in range(no_of_change_points-1, -1, -1 ):  \n",
        "              if(experimental_dataset.change_points_of_train_data_set[fold_no][attribute_number][i] < modified_attribute_value1 ):\n",
        "                counter1 = i\n",
        "                break \n",
        "            # print('modified_attribute_value1='+str(modified_attribute_value1))# for testing  \n",
        "            # print('counter1='+str(counter1))# for testing \n",
        "            modified_attribute_value1 = experimental_dataset.change_points_of_train_data_set[fold_no][attribute_number][counter1]\n",
        "            # print('modified_attribute_value1='+str(modified_attribute_value1))# for testing  \n",
        "          if(str(modified_attribute_value2) == str(experimental_dataset.change_points_of_train_data_set[fold_no][attribute_number][len(experimental_dataset.change_points_of_train_data_set[fold_no][attribute_number])-1])):\n",
        "            pass      \n",
        "          elif(str(modified_attribute_value2) != str(np.nan)):\n",
        "            counter2 = -1\n",
        "            no_of_change_points = len(experimental_dataset.change_points_of_train_data_set[fold_no][attribute_number])\n",
        "            for i in range(0, no_of_change_points-1):  \n",
        "              if(experimental_dataset.change_points_of_train_data_set[fold_no][attribute_number][i] > modified_attribute_value2):\n",
        "                counter2 = i\n",
        "                break          \n",
        "            # print('modified_attribute_value2='+str(modified_attribute_value2))# for testing \n",
        "            # print('counter2='+str(counter2))# for testing \n",
        "            modified_attribute_value2 = experimental_dataset.change_points_of_train_data_set[fold_no][attribute_number][counter2]\n",
        "            # print('modified_attribute_value2='+str(modified_attribute_value2))# for testing\n",
        "        dna = []\n",
        "        dna.append(modified_attribute_value1)\n",
        "        dna.append(modified_attribute_value2)\n",
        "        # print(dna)#for testing        \n",
        "        dna_of_chromosome.append(dna)\n",
        "\n",
        "      else: #for categorical features\n",
        "        random_number5 = random.uniform(0, 1)\n",
        "        if(random_number5>experimental_dataset.attribute_selection_probability_list[fold_no][attribute_number]):\n",
        "          modified_attribute_value1 = np.nan\n",
        "          modified_attribute_value2 = np.nan\n",
        "        else:\n",
        "          attribute_value1 = experimental_dataset.train_list_with_NaN[fold_no].iat[random_number1,attribute_number]\n",
        "          attribute_value2 = experimental_dataset.train_list_with_NaN[fold_no].iat[random_number2,attribute_number]\n",
        "          # print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')# for testing \n",
        "          # print('attribute_value1='+str(attribute_value1))# for testing     \n",
        "          # print('attribute_value2='+str(attribute_value2))# for testing \n",
        "          # print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')# for testing \n",
        "          if(str(attribute_value1) == str(np.nan) and str(attribute_value2) != str(np.nan)): \n",
        "            modified_attribute_value1 = attribute_value2\n",
        "            modified_attribute_value2 = attribute_value2            \n",
        "          elif(str(attribute_value1) != str(np.nan) and str(attribute_value2) == str(np.nan)): \n",
        "            modified_attribute_value1 = attribute_value1\n",
        "            modified_attribute_value2 = attribute_value1  \n",
        "          else:\n",
        "            modified_attribute_value1 = attribute_value1\n",
        "            modified_attribute_value2 = attribute_value2           \n",
        "        dna = []\n",
        "        if(str(modified_attribute_value1) == str(np.nan) and str(modified_attribute_value1) == str(np.nan)): \n",
        "          dna.append(np.nan)\n",
        "        else:\n",
        "          for value_number in range(0, experimental_dataset.no_of_different_attribute_values[fold_no][attribute_number]):                            \n",
        "            if((str(modified_attribute_value1) == str(experimental_dataset.sorted_unique_attribute_values_of_train_dataset[fold_no][attribute_number][value_number])) or (str(modified_attribute_value2) == str(experimental_dataset.sorted_unique_attribute_values_of_train_dataset[fold_no][attribute_number][value_number]))): \n",
        "              # print('Within if')\n",
        "              dna.append(1)\n",
        "            else:\n",
        "              random_number6 = random.uniform(0, 1)\n",
        "              if(random_number6 < 0.5):\n",
        "                dna.append(1)\n",
        "              else:\n",
        "                dna.append(0)\n",
        "        # print(dna)#for testing       \n",
        "        dna_of_chromosome.append(dna)\n",
        "    return dna_of_chromosome\n",
        "\n",
        "\n",
        "  def show_chromosome(self):\n",
        "    print(*self.dna_of_chromosome, sep = ',') \n",
        "\n",
        "    \n",
        "  def show_chromosome_with_fitness(self):\n",
        "    print(*self.dna_of_chromosome, sep = ',') \n",
        "    print('Class Label ='+str(self.class_label_of_chromosome)) \n",
        "    print('Confidence ='+str(self.Confidence)) \n",
        "    print('Coverage ='+str(self.Coverage)) \n",
        "    print('Number of valid attributes ='+str(self.no_of_valid_attributes))  \n",
        "      \n"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk7pof2cJfVI",
        "colab_type": "text"
      },
      "source": [
        "**P2_MOGA Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxYHpDBTJGgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class P2_MOGA:\n",
        "\n",
        "  def __init__(self,number_of_call_of_P2_MOGA,experimental_dataset,fold_no,pareto_population_from_P1MOGA,max_number_of_generation_of_BPMOGA,max_number_of_generation_of_P2MOGA,size_of_initial_population_of_P2MOGA,min_rule_prob_P2,max_rule_prob_P2,min_cross_prob_P2,max_cross_prob_P2,min_mu_prob_P2,max_mu_prob_P2):\n",
        "    print('Within P2_MOGA class')\n",
        "    sorted_population_from_P1_MOGA = pareto_population_from_P1MOGA.sortingCSRs()\n",
        "    # print('Sorted Population from P1_MOGA at P2_MOGA') # for testing\n",
        "    # sorted_population_from_P1_MOGA.show_population()\n",
        "    # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "    starting_generation_of_P2 = number_of_call_of_P2_MOGA*max_number_of_generation_of_P2MOGA\n",
        "    class_rules_prob_P2 = self.calculate_class_rules_prob_P2(starting_generation_of_P2,max_number_of_generation_of_BPMOGA,min_rule_prob_P2,max_rule_prob_P2)\n",
        "    for generationP2 in range(0, max_number_of_generation_of_P2MOGA):\n",
        "    # for generationP2 in range(0, 4): # for testing\n",
        "      print('Generation of P2_MOGA ='+str(generationP2))\n",
        "      if(generationP2!=0 and generationP2%2!=0):\n",
        "        population_before_crossover_of_P2=self.Pareto_population_of_P2\n",
        "      else:\n",
        "        population_before_crossover_of_P2=population_of_P2()        \n",
        "        population_before_crossover_of_P2.set_values(sorted_population_from_P1_MOGA,size_of_initial_population_of_P2MOGA,class_rules_prob_P2)        \n",
        "        if(generationP2==0):\n",
        "          self.Pareto_population_of_P2=population_before_crossover_of_P2\n",
        "      # print('Population before crossover')#for testing\n",
        "      # population_before_crossover_of_P2.show_population_with_fitnesses()#for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      crossover_probability_P2 = self.calculate_crossover_probability_P2(generationP2,max_number_of_generation_of_P2MOGA,min_cross_prob_P2,max_cross_prob_P2)\n",
        "      population_after_crossover_of_P2 = self.crossover_P2(sorted_population_from_P1_MOGA,crossover_probability_P2,population_before_crossover_of_P2)\n",
        "      # print('Population after crossover')#for testing\n",
        "      # population_after_crossover_of_P2.show_population_with_fitnesses()#for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      mutation_probability_P2 = self.calculate_mutation_probability_P2(generationP2,max_number_of_generation_of_P2MOGA,min_mu_prob_P2,max_mu_prob_P2)\n",
        "      mutation_probability_P2 = 0.5 #for testing\n",
        "      # print('mutation_probability_P2='+str(mutation_probability_P2))#for testing\n",
        "      # print('Population before mutation')#for testing\n",
        "      # population_before_crossover_of_P2.show_population_with_fitnesses()#for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_mutation_of_P2 = self.mutation_P2(sorted_population_from_P1_MOGA,mutation_probability_P2,population_before_crossover_of_P2)\n",
        "      # print('Population after mutation')#for testing\n",
        "      # population_after_mutation_of_P2.show_population_with_fitnesses()#for testing\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_combination_of_P2 = self.combination_P2(sorted_population_from_P1_MOGA,self.Pareto_population_of_P2,population_after_crossover_of_P2,population_after_mutation_of_P2)\n",
        "      #print('Population after combination')#for testing\n",
        "      #population_after_combination_of_P2.show_population_with_fitnesses()#for testing\n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_eliminating_unnecessary_CSRs = self.eliminate_unnecessary_CSRs(experimental_dataset,fold_no,sorted_population_from_P1_MOGA,population_after_combination_of_P2)\n",
        "      #print('population_after_eliminating_unnecessary_CSRs')#for testing\n",
        "      #population_after_eliminating_unnecessary_CSRs.show_population_with_fitnesses()#for testing\n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_eliminating_duplicate_CRs =  self.eliminate_duplicate_CRs(experimental_dataset,fold_no,sorted_population_from_P1_MOGA,population_after_eliminating_unnecessary_CSRs)\n",
        "      #print('population_after_eliminating_duplicate_CRs')#for testing\n",
        "      #population_after_eliminating_duplicate_CRs.show_population_with_fitnesses()#for testing\n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      population_after_fitness_calculation = self.fitness_calculation_P2(experimental_dataset,fold_no,sorted_population_from_P1_MOGA,population_after_eliminating_duplicate_CRs)\n",
        "      #print('population_after_fitness_calculation')#for testing\n",
        "      #population_after_fitness_calculation.show_population_with_fitnesses()#for testing\n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      self.Pareto_population_of_P2 = population_after_fitness_calculation.pareto_selection_P2()\n",
        "      #print('population_after_pareto_slection')#for testing\n",
        "      #self.Pareto_population_of_P2.show_population_with_fitnesses()#for testing\n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "      if(self.Pareto_population_of_P2.size_of_population_of_P2 > 20):\n",
        "        sorted_population_of_P2 = self.Pareto_population_of_P2.sortingCRs()        \n",
        "        top_20_sorted_population_of_P2 = sorted_population_of_P2.select_top_20_CRs()        \n",
        "        self.Pareto_population_of_P2 = top_20_sorted_population_of_P2\n",
        "      #print('top_20_sorted_population_of_P2') # for testing  \n",
        "      #self.Pareto_population_of_P2.show_population_with_fitnesses() # for testing  \n",
        "      #print(\"---------------------------------------------------------------------------------------\") # for testing \n",
        "  \n",
        "\n",
        "\n",
        "  def fitness_calculation_P2(self,experimental_dataset,fold_no,sorted_population_from_P1_MOGA,population_after_eliminating_duplicate_CSRs):\n",
        "    list_of_CRs = []\n",
        "    for chromosome_no in range(0, population_after_eliminating_duplicate_CSRs.size_of_population_of_P2):\n",
        "    #for chromosome_no in range(0, 1): #for testing\n",
        "      CR = population_after_eliminating_duplicate_CSRs.chromosomes_of_P2[chromosome_no]\n",
        "      if(str(CR.total_confidence) == str(np.nan)):        \n",
        "        CR.fitness_calculation_P2(experimental_dataset,fold_no,sorted_population_from_P1_MOGA)\n",
        "      list_of_CRs.append(CR)\n",
        "    population_after_fitness_calculation_P2 = population_of_P2()\n",
        "    population_after_fitness_calculation_P2.set_values2(sorted_population_from_P1_MOGA,population_after_eliminating_duplicate_CSRs.size_of_population_of_P2,list_of_CRs)\n",
        "    return population_after_fitness_calculation_P2\n",
        "\n",
        "\n",
        "\n",
        "  def eliminate_duplicate_CRs(self,experimental_dataset,fold_no,sorted_population_from_P1_MOGA,population_after_eliminating_unnecessary_CSRs):\n",
        "    #print('Size before='+str(population_after_eliminating_unnecessary_CSRs.size_of_population_of_P2))# for testing\n",
        "    list_of_unique_chromosomes = []\n",
        "    list_of_unique_dna = []\n",
        "    for chromosome_no in range(0, population_after_eliminating_unnecessary_CSRs.size_of_population_of_P2):\n",
        "      if(population_after_eliminating_unnecessary_CSRs.chromosomes_of_P2[chromosome_no].dna_of_P2 in list_of_unique_dna):\n",
        "        pass\n",
        "      else:\n",
        "        list_of_unique_dna.append(population_after_eliminating_unnecessary_CSRs.chromosomes_of_P2[chromosome_no].dna_of_P2)\n",
        "        list_of_unique_chromosomes.append(population_after_eliminating_unnecessary_CSRs.chromosomes_of_P2[chromosome_no])\n",
        "    size_of_population_of_P2 = len(list_of_unique_dna)\n",
        "    population_after_eliminating_duplicate_CRs = population_of_P2()\n",
        "    population_after_eliminating_duplicate_CRs.set_values3(size_of_population_of_P2,list_of_unique_chromosomes)\n",
        "    #print('Size after='+str(population_after_eliminating_duplicate_CRs.size_of_population_of_P2))# for testing\n",
        "    return population_after_eliminating_duplicate_CRs\n",
        "\n",
        "\n",
        "  def eliminate_unnecessary_CSRs(self,experimental_dataset,fold_no,sorted_population_from_P1_MOGA,population_after_combination_of_P2):    \n",
        "    for chromosome_no in range(0, population_after_combination_of_P2.size_of_population_of_P2):\n",
        "    # for chromosome_no in range(0, 1): # for testing\n",
        "      # print('chromosome_no='+str(chromosome_no))#for testing\n",
        "      dna_of_chromosome = population_after_combination_of_P2.chromosomes_of_P2[chromosome_no].dna_of_P2\n",
        "      flag_list =  [False for i in range(0,experimental_dataset.no_of_records_in_train_list[fold_no])]\n",
        "      # print(*dna_of_chromosome, sep = ',')\n",
        "      modified_dna_of_CR = []\n",
        "      for gene_no in range(0, len(dna_of_chromosome)):\n",
        "      # for gene_no in range(0, 10):# for testing\n",
        "        dna_flag = False\n",
        "        if(dna_of_chromosome[gene_no] == 1):\n",
        "          CSR = sorted_population_from_P1_MOGA.chromosomes[gene_no]\n",
        "          # CSR.show_chromosome_with_fitness()#for testing\n",
        "          for record_no in range(0, experimental_dataset.no_of_records_in_train_list[fold_no]):\n",
        "            if(flag_list[record_no] == False):\n",
        "              # flag_list[record_no]=CSR.check_coverage_of_a_record_by_a_chromosome(experimental_dataset,fold_no,record_no)\n",
        "              if(record_no in CSR.list_of_records_covered):\n",
        "                flag_list[record_no] = True\n",
        "              # print(str(record_no)+str(flag_list[record_no]))#for testing\n",
        "              if(flag_list[record_no] == True):\n",
        "                dna_flag = True\n",
        "        if(dna_flag == True):\n",
        "          # print('modified_dna_of_CR='+'1')\n",
        "          modified_dna_of_CR.append(1)\n",
        "        else:\n",
        "          # print('modified_dna_of_CR='+'0')\n",
        "          modified_dna_of_CR.append(0)\n",
        "\n",
        "      population_after_combination_of_P2.chromosomes_of_P2[chromosome_no].dna_of_P2 = modified_dna_of_CR\n",
        "      # print(*modified_dna_of_CR, sep = ',')\n",
        "      # print(\"---------------------------------------------------------------------------------------\") # for testing     \n",
        "    \n",
        "    return population_after_combination_of_P2\n",
        "    \n",
        "    \n",
        "  def combination_P2(self,sorted_population_from_P1_MOGA,Pareto_population_of_P2,population_after_crossover_of_P2,population_after_mutation_of_P2):\n",
        "    list_of_chromosomes = []\n",
        "    size_of_population_after_combination = 0\n",
        "    for chromosome_no in range(0, Pareto_population_of_P2.size_of_population_of_P2):\n",
        "      list_of_chromosomes.append(Pareto_population_of_P2.chromosomes_of_P2[chromosome_no])\n",
        "      size_of_population_after_combination=size_of_population_after_combination+1\n",
        "    for chromosome_no in range(0, population_after_crossover_of_P2.size_of_population_of_P2):\n",
        "      list_of_chromosomes.append(population_after_crossover_of_P2.chromosomes_of_P2[chromosome_no]) \n",
        "      size_of_population_after_combination=size_of_population_after_combination+1\n",
        "    for chromosome_no in range(0, population_after_mutation_of_P2.size_of_population_of_P2):\n",
        "      list_of_chromosomes.append(population_after_mutation_of_P2.chromosomes_of_P2[chromosome_no]) \n",
        "      size_of_population_after_combination=size_of_population_after_combination+1\n",
        "    population_after_combination_P2 = population_of_P2()\n",
        "    population_after_combination_P2.set_values3(size_of_population_after_combination,list_of_chromosomes)\n",
        "    return population_after_combination_P2\n",
        "\n",
        "\n",
        "  def mutation_P2(self,sorted_population_from_P1_MOGA,mutation_probability_P2,population_before_mutation_of_P2):\n",
        "    population_after_mutation_of_P2 = copy.deepcopy(population_before_mutation_of_P2)    \n",
        "    for chromosome_no in range(0, population_before_mutation_of_P2.size_of_population_of_P2):         \n",
        "      population_after_mutation_of_P2.chromosomes_of_P2[chromosome_no].total_confidence = np.nan  \n",
        "      population_after_mutation_of_P2.chromosomes_of_P2[chromosome_no].total_coverage = np.nan  \n",
        "      population_after_mutation_of_P2.chromosomes_of_P2[chromosome_no].no_of_CSRs = np.nan  \n",
        "      population_after_mutation_of_P2.chromosomes_of_P2[chromosome_no].default_class_label = np.nan        \n",
        "      for gene_no in range(0, len(population_after_mutation_of_P2.chromosomes_of_P2[chromosome_no].dna_of_P2)):        \n",
        "        random_number = random.uniform(0, 1)\n",
        "        if(random_number<mutation_probability_P2):         \n",
        "          if(population_before_mutation_of_P2.chromosomes_of_P2[chromosome_no].dna_of_P2[gene_no]==1):\n",
        "            population_after_mutation_of_P2.chromosomes_of_P2[chromosome_no].dna_of_P2[gene_no] = 0\n",
        "          else:\n",
        "            population_after_mutation_of_P2.chromosomes_of_P2[chromosome_no].dna_of_P2[gene_no] = 1\n",
        "    return population_after_mutation_of_P2\n",
        "\n",
        "\n",
        "  def calculate_mutation_probability_P2(self,generationP2,max_number_of_generation_of_P2MOGA,min_mu_prob_P2,max_mu_prob_P2):\n",
        "    mutation_probability_P2 = (max_mu_prob_P2 - min_mu_prob_P2)*(max_number_of_generation_of_P2MOGA-1-generationP2)/(max_number_of_generation_of_P2MOGA-1)+min_mu_prob_P2\n",
        "    # print('mutation_probability_P2='+str(mutation_probability_P2))#for testing\n",
        "    return mutation_probability_P2\n",
        "\n",
        "\n",
        "  def calculate_crossover_probability_P2(self,generationP2,max_number_of_generation_of_P2MOGA,min_cross_prob_P2,max_cross_prob_P2):\n",
        "    crossover_probability_P2 = (max_cross_prob_P2 - min_cross_prob_P2)*generationP2/(max_number_of_generation_of_P2MOGA-1)+min_cross_prob_P2\n",
        "    # print('crossover_probability P2='+str(crossover_probability_P2))#for testing\n",
        "    return crossover_probability_P2\n",
        "\n",
        "\n",
        "  def crossover_P2(self,sorted_population_from_P1_MOGA,crossover_probability_P2,population_before_crossover_of_P2):\n",
        "    flag_list =  [True for i in range(0,population_before_crossover_of_P2.size_of_population_of_P2)]     \n",
        "    number_of_crossover = population_before_crossover_of_P2.size_of_population_of_P2*crossover_probability_P2\n",
        "    crossover_count = 0\n",
        "    list_of_dna_after_crossover = []\n",
        "    while(crossover_count<number_of_crossover):\n",
        "      random_number1 = random.randint(0,population_before_crossover_of_P2.size_of_population_of_P2-1)\n",
        "      random_number2 = random.randint(0,population_before_crossover_of_P2.size_of_population_of_P2-1)\n",
        "      if((flag_list[random_number1] == True) and (flag_list[random_number2] == True) and random_number1 != random_number2):\n",
        "        dna_chromo1 = population_before_crossover_of_P2.chromosomes_of_P2[random_number1].dna_of_P2\n",
        "        dna_chromo2 = population_before_crossover_of_P2.chromosomes_of_P2[random_number2].dna_of_P2\n",
        "        random_number3 = random.randint(1,len(dna_chromo1)-1)\n",
        "        left_part_of_dna_chromo1 = dna_chromo1[0:random_number3]        \n",
        "        right_part_of_dna_chromo1 = dna_chromo1[random_number3:len(dna_chromo1)]\n",
        "        left_part_of_dna_chromo2 = dna_chromo2[0:random_number3]\n",
        "        right_part_of_dna_chromo2 = dna_chromo2[random_number3:len(dna_chromo2)]\n",
        "        left_part_of_dna_chromo1.extend(right_part_of_dna_chromo2)\n",
        "        left_part_of_dna_chromo2.extend(right_part_of_dna_chromo1)            \n",
        "        modified_dna_chromo1 = left_part_of_dna_chromo1\n",
        "        modified_dna_chromo2 = left_part_of_dna_chromo2    \n",
        "        # print(*dna_chromo1, sep = ',') # for testing\n",
        "        # print(*dna_chromo2, sep = ',') # for testing  \n",
        "        # print('random_number3 =' + str(random_number3)) # for testing  \n",
        "        # print(*modified_dna_chromo1, sep = ',') # for testing\n",
        "        # print(*modified_dna_chromo2, sep = ',') # for testing  \n",
        "        # print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "        list_of_dna_after_crossover.append(modified_dna_chromo1)\n",
        "        list_of_dna_after_crossover.append(modified_dna_chromo2)\n",
        "        crossover_count = crossover_count +1\n",
        "    size_of_population_of_P2 = len(list_of_dna_after_crossover)\n",
        "    population_after_crossover_of_P2 = population_of_P2()\n",
        "    population_after_crossover_of_P2.set_values1(sorted_population_from_P1_MOGA,size_of_population_of_P2,list_of_dna_after_crossover)\n",
        "    return population_after_crossover_of_P2\n",
        "\n",
        "\n",
        "  def calculate_class_rules_prob_P2(self,starting_generation_of_P2,max_number_of_generation_of_BPMOGA,min_rule_prob_P2,max_rule_prob_P2):\n",
        "    class_rules_prob_P2 = (max_rule_prob_P2 - min_rule_prob_P2)*starting_generation_of_P2/max_number_of_generation_of_BPMOGA+min_rule_prob_P2\n",
        "    # print('class_rules_prob_P2='+str(class_rules_prob_P2))#for testing\n",
        "    return class_rules_prob_P2\n",
        "   \n"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBXABYcnKfeK",
        "colab_type": "text"
      },
      "source": [
        "**population_of_P2 Class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mScFvO3KTOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class population_of_P2:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "    \n",
        "\n",
        "  def set_values(self,sorted_population_from_P1_MOGA,size_of_population_of_P2,class_rules_prob_P2):\n",
        "    self.size_of_population_of_P2 = size_of_population_of_P2\n",
        "    # self.show_population_size_of_P2()# for testing\n",
        "    self.chromosomes_of_P2  = self.create_population_of_P2(sorted_population_from_P1_MOGA,size_of_population_of_P2,class_rules_prob_P2)\n",
        "\n",
        "\n",
        "  def set_values1(self,sorted_population_from_P1_MOGA,size_of_population_of_P2,list_of_dna_of_P2):\n",
        "    self.size_of_population_of_P2 = size_of_population_of_P2\n",
        "    self.chromosomes_of_P2 = self.create_population_of_P21(sorted_population_from_P1_MOGA,size_of_population_of_P2,list_of_dna_of_P2)\n",
        "\n",
        "\n",
        "  def set_values2(self,sorted_population_from_P1_MOGA,size_of_population_of_P2,list_of_CRs):\n",
        "    self.size_of_population_of_P2 = size_of_population_of_P2\n",
        "    self.chromosomes_of_P2 = self.create_population_of_P22(sorted_population_from_P1_MOGA,size_of_population_of_P2,list_of_CRs)  \n",
        "    \n",
        "    \n",
        "  def set_values3(self,size_of_population,list_of_CRs):\n",
        "    self.size_of_population_of_P2 = size_of_population\n",
        "    self.chromosomes_of_P2 = self.create_population_of_P23(size_of_population,list_of_CRs)\n",
        "\n",
        "\n",
        "  def show_population_size_of_P2(self):\n",
        "    print('Size of population of P2='+str(self.size_of_population_of_P2))\n",
        "\n",
        "\n",
        "  def create_population_of_P23(self,size_of_population_of_P2,list_of_CRs):\n",
        "    chromosomes_of_P2 = []\n",
        "    for chromosome_no in range(0, size_of_population_of_P2):\n",
        "      chrom_of_P2 = chromosome_of_P2()\n",
        "      chrom_of_P2.create_chromosome_of_P22(list_of_CRs[chromosome_no].sorted_population_from_P1_MOGA,list_of_CRs[chromosome_no])\n",
        "      chromosomes_of_P2.append(chrom_of_P2)\n",
        "    return chromosomes_of_P2\n",
        "\n",
        "\n",
        "  def create_population_of_P22(self,sorted_population_from_P1_MOGA,size_of_population_of_P2,list_of_CRs):\n",
        "    chromosomes_of_P2 = []\n",
        "    for chromosome_no in range(0, size_of_population_of_P2):\n",
        "      chrom_of_P2 = chromosome_of_P2()\n",
        "      chrom_of_P2.create_chromosome_of_P22(sorted_population_from_P1_MOGA,list_of_CRs[chromosome_no])\n",
        "      chromosomes_of_P2.append(chrom_of_P2)\n",
        "    return chromosomes_of_P2\n",
        "\n",
        "\n",
        "  def create_population_of_P21(self,sorted_population_from_P1_MOGA,size_of_population_of_P2,list_of_dna_of_P2):\n",
        "    chromosomes_of_P2 = []\n",
        "    for chromosome_no in range(0, size_of_population_of_P2):\n",
        "      chrom_of_P2 = chromosome_of_P2()\n",
        "      chrom_of_P2.create_chromosome_of_P21(sorted_population_from_P1_MOGA,list_of_dna_of_P2[chromosome_no])\n",
        "      chromosomes_of_P2.append(chrom_of_P2)\n",
        "    return chromosomes_of_P2\n",
        "\n",
        "\n",
        "  def create_population_of_P2(self,sorted_population_from_P1_MOGA,size_of_population_of_P2,class_rules_prob_P2):\n",
        "    no_of_chromosome = 0\n",
        "    chromosomes_of_P2 = []\n",
        "    class_labels_in_CSRs = self.find_class_labels_in_CSRs(sorted_population_from_P1_MOGA)    \n",
        "    # print(*class_labels_in_CSRs, sep = \", \") # for testing\n",
        "    no_of_class_labels_in_training_dataset=len(class_labels_in_CSRs)\n",
        "    # print('no_of_class_labels_in_training_dataset='+str(no_of_class_labels_in_training_dataset)) # for testing\n",
        "    while (no_of_chromosome < size_of_population_of_P2):      \n",
        "      chrom_of_P2 = chromosome_of_P2()\n",
        "      chrom_of_P2.create_chromosome_of_P2(sorted_population_from_P1_MOGA,class_rules_prob_P2)\n",
        "      class_labels_in_chosen_CSRs = self.find_class_labels_in_chosen_CSRs(sorted_population_from_P1_MOGA,chrom_of_P2)\n",
        "      # print(*class_labels_in_chosen_CSRs, sep = \", \") # for testing\n",
        "      no_of_class_labels_in_chosen_CSRs=len(class_labels_in_chosen_CSRs)\n",
        "      # print('no_of_class_labels_in_chosen_CSRs='+str(no_of_class_labels_in_chosen_CSRs)) # for testing\n",
        "      if(no_of_class_labels_in_training_dataset==no_of_class_labels_in_chosen_CSRs):\n",
        "        chromosomes_of_P2.append(chrom_of_P2)\n",
        "        no_of_chromosome = no_of_chromosome +1\n",
        "    return chromosomes_of_P2\n",
        "    \n",
        "\n",
        "  def find_class_labels_in_CSRs(self,sorted_population_from_P1_MOGA):\n",
        "    # print('sorted_population_from_P1_MOGA.population_size='+str(sorted_population_from_P1_MOGA.size_of_population))\n",
        "    list_of_class_labels_in_CSRs = []\n",
        "    for CSR_no in range(0, sorted_population_from_P1_MOGA.size_of_population):\n",
        "      if sorted_population_from_P1_MOGA.chromosomes[CSR_no].class_label_of_chromosome in list_of_class_labels_in_CSRs:\n",
        "        pass\n",
        "      else:\n",
        "        list_of_class_labels_in_CSRs.append(sorted_population_from_P1_MOGA.chromosomes[CSR_no].class_label_of_chromosome)\n",
        "    return list_of_class_labels_in_CSRs\n",
        "\n",
        "\n",
        "  def find_class_labels_in_chosen_CSRs(self,sorted_population_from_P1_MOGA,chrom_of_P2):\n",
        "    # print('sorted_population_from_P1_MOGA.population_size='+str(sorted_population_from_P1_MOGA.size_of_population))\n",
        "    list_of_class_labels_in_chosen_CSRs = []\n",
        "    for CSR_no in range(0, sorted_population_from_P1_MOGA.size_of_population):\n",
        "      if(chrom_of_P2.dna_of_P2[CSR_no] == 1):\n",
        "        if sorted_population_from_P1_MOGA.chromosomes[CSR_no].class_label_of_chromosome in list_of_class_labels_in_chosen_CSRs:\n",
        "          pass\n",
        "        else:\n",
        "          list_of_class_labels_in_chosen_CSRs.append(sorted_population_from_P1_MOGA.chromosomes[CSR_no].class_label_of_chromosome)\n",
        "    return list_of_class_labels_in_chosen_CSRs\n",
        "\n",
        "\n",
        "  def pareto_selection_P2(self):    \n",
        "    flag_list =  [True for i in range(0,self.size_of_population_of_P2)] \n",
        "    for outer_loop in range(0, self.size_of_population_of_P2):      \n",
        "      TCon1 = self.chromosomes_of_P2[outer_loop].total_confidence\n",
        "      TCov1 = self.chromosomes_of_P2[outer_loop].total_coverage\n",
        "      NCSR1 = self.chromosomes_of_P2[outer_loop].no_of_CSRs\n",
        "      for inner_loop in range(0, self.size_of_population_of_P2):        \n",
        "        TCon2 = self.chromosomes_of_P2[inner_loop].total_confidence\n",
        "        TCov2 = self.chromosomes_of_P2[inner_loop].total_coverage\n",
        "        NCSR2 = self.chromosomes_of_P2[inner_loop].no_of_CSRs\n",
        "        if(outer_loop != inner_loop):\n",
        "          if(((TCon1>TCon2) and (TCov1>TCov2) and (NCSR1<NCSR2)) \n",
        "            or ((TCon1>TCon2) and (TCov1>TCov2) and (NCSR1==NCSR2)) \n",
        "            or ((TCon1>TCon2) and (TCov1==TCov2) and (NCSR1<NCSR2)) \n",
        "            or ((TCon1==TCon2) and (TCov1>TCov2) and (NCSR1<NCSR2)) \n",
        "            or ((TCon1>TCon2) and (TCov1==TCov2) and (NCSR1==NCSR2)) \n",
        "            or ((TCon1==TCon2) and (TCov1>TCov2) and (NCSR1==NCSR2)) \n",
        "            or ((TCon1==TCon2) and (TCov1==TCov2) and (NCSR1<NCSR2))):\n",
        "            flag_list[inner_loop] = False  \n",
        "            break\n",
        "    pareto_population_of_P2 = population_of_P2() \n",
        "    list_of_chromosomes_of_P2 = []       \n",
        "    for counter in range(0, self.size_of_population_of_P2):\n",
        "      if(flag_list[counter] == True):\n",
        "        list_of_chromosomes_of_P2.append(self.chromosomes_of_P2[counter])\n",
        "    size_of_population_of_P2 = len(list_of_chromosomes_of_P2)\n",
        "    pareto_population_of_P2.set_values3(size_of_population_of_P2,list_of_chromosomes_of_P2)\n",
        "    return pareto_population_of_P2   \n",
        "\n",
        "\n",
        "  def combine_population_P2(self,population_from_earlier_gen_P2):\n",
        "    self.size_of_population_of_P2 = self.size_of_population_of_P2 + population_from_earlier_gen_P2.size_of_population_of_P2\n",
        "    for chromosome_no in range(0, population_from_earlier_gen_P2.size_of_population_of_P2):  \n",
        "      self.chromosomes_of_P2.append(population_from_earlier_gen_P2.chromosomes_of_P2[chromosome_no]) \n",
        "    return self\n",
        "\n",
        "\n",
        "  def sortingCRs(self): \n",
        "    flag_list =  [True for i in range(0, self.size_of_population_of_P2)]   \n",
        "    counter=0\n",
        "    list_of_chromosomes_of_P2 = []\n",
        "    for loop_counter in range(0, self.size_of_population_of_P2): \n",
        "      Tcon = 0\n",
        "      Tcov = 0\n",
        "      NOCSR = 10000\n",
        "      chromosome_number=-1\n",
        "      for chromosome_no in range(0, self.size_of_population_of_P2): \n",
        "        if(flag_list[chromosome_no] == True):\n",
        "          if(Tcon < self.chromosomes_of_P2[chromosome_no].total_confidence ):\n",
        "            chromosome_number=chromosome_no\n",
        "            Tcon = self.chromosomes_of_P2[chromosome_no].total_confidence\n",
        "            Tcov = self.chromosomes_of_P2[chromosome_no].total_coverage\n",
        "            NOCSR = self.chromosomes_of_P2[chromosome_no].no_of_CSRs\n",
        "          elif(Tcon == self.chromosomes_of_P2[chromosome_no].total_confidence ):\n",
        "            if(Tcov < self.chromosomes_of_P2[chromosome_no].total_coverage):\n",
        "              chromosome_number=chromosome_no\n",
        "              Tcov = self.chromosomes_of_P2[chromosome_no].total_coverage\n",
        "              NOCSR = self.chromosomes_of_P2[chromosome_no].no_of_CSRs\n",
        "            elif(Tcov == self.chromosomes_of_P2[chromosome_no].total_coverage):\n",
        "              if(NOCSR > self.chromosomes_of_P2[chromosome_no].no_of_CSRs):\n",
        "                chromosome_number=chromosome_no\n",
        "                NOCSR = self.chromosomes_of_P2[chromosome_no].no_of_CSRs\n",
        "              elif(NOCSR == self.chromosomes_of_P2[chromosome_no].no_of_CSRs):\n",
        "                chromosome_number=chromosome_no\n",
        "      flag_list [chromosome_number] = False\n",
        "      list_of_chromosomes_of_P2.append(self.chromosomes_of_P2[chromosome_number])\n",
        "      counter= counter+1\n",
        "    size_of_population_of_P2 = len(list_of_chromosomes_of_P2)\n",
        "    sorted_population = population_of_P2() \n",
        "    sorted_population.set_values3(size_of_population_of_P2,list_of_chromosomes_of_P2)\n",
        "    return sorted_population\n",
        "\n",
        "\n",
        "  def select_top_20_CRs(self): \n",
        "    top_20_CRs = self.chromosomes_of_P2[:20]\n",
        "    sorted_population = population_of_P2() \n",
        "    sorted_population.set_values3(20,top_20_CRs)\n",
        "    return sorted_population\n",
        "\n",
        "\n",
        "  def find_max_Total_confidence(self): \n",
        "    max_T_con = 0\n",
        "    for CR_no in range(0, self.size_of_population_of_P2): \n",
        "      if (max_T_con < self.chromosomes_of_P2[CR_no].total_confidence):\n",
        "        max_T_con = self.chromosomes_of_P2[CR_no].total_confidence\n",
        "    return max_T_con\n",
        "\n",
        "\n",
        "  def find_max_Total_coverage(self): \n",
        "    max_T_cov = 0\n",
        "    for CR_no in range(0, self.size_of_population_of_P2): \n",
        "      if (max_T_cov < self.chromosomes_of_P2[CR_no].total_coverage):\n",
        "        max_T_cov = self.chromosomes_of_P2[CR_no].total_coverage\n",
        "    return max_T_cov\n",
        "\n",
        "\n",
        "  def find_min_CSRs(self): \n",
        "    min_CSRs = 10000\n",
        "    for CR_no in range(0, self.size_of_population_of_P2): \n",
        "      if (min_CSRs > self.chromosomes_of_P2[CR_no].no_of_CSRs):\n",
        "        min_CSRs = self.chromosomes_of_P2[CR_no].no_of_CSRs\n",
        "    return min_CSRs   \n",
        "\n",
        "\n",
        "  def show_population(self):\n",
        "    print('Size of Population = '+ str(self.size_of_population_of_P2))\n",
        "    for chromosome_no in range(0, self.size_of_population_of_P2):  \n",
        "      self.chromosomes_of_P2[chromosome_no].show_chromosome()\n",
        "\n",
        "\n",
        "  def show_population_with_fitnesses(self):\n",
        "    print('Size of Population = '+ str(self.size_of_population_of_P2))\n",
        "    for chromosome_no in range(0, self.size_of_population_of_P2):  \n",
        "      self.chromosomes_of_P2[chromosome_no].show_CR()\n",
        "      \n"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUzdpjR6rVfH",
        "colab_type": "text"
      },
      "source": [
        "**chromosome_of_P2 Class**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5CDbmi749kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class chromosome_of_P2:\n",
        "\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def create_chromosome_of_P22(self,sorted_population_from_P1_MOGA,CR):\n",
        "    self.sorted_population_from_P1_MOGA = sorted_population_from_P1_MOGA\n",
        "    self.dna_of_P2 = CR.dna_of_P2\n",
        "    self.total_confidence = CR.total_confidence    \n",
        "    self.total_coverage = CR.total_coverage    \n",
        "    self.no_of_CSRs = CR.no_of_CSRs\n",
        "    self.default_class_label = CR.default_class_label\n",
        "\n",
        "    \n",
        "  def create_chromosome_of_P21(self,sorted_population_from_P1_MOGA,dna_of_P2):\n",
        "    self.sorted_population_from_P1_MOGA = sorted_population_from_P1_MOGA\n",
        "    self.dna_of_P2 = dna_of_P2\n",
        "    self.total_confidence = np.nan    \n",
        "    self.total_coverage = np.nan    \n",
        "    self.no_of_CSRs = np.nan\n",
        "    self.default_class_label = np.nan\n",
        "\n",
        "\n",
        "  def create_chromosome_of_P2(self,sorted_population_from_P1_MOGA,class_rules_prob_P2):\n",
        "    self.sorted_population_from_P1_MOGA = sorted_population_from_P1_MOGA\n",
        "    self.dna_of_P2 = []\n",
        "    for CSR_no in range(0, sorted_population_from_P1_MOGA.size_of_population):\n",
        "      random_number = random.uniform(0,1)\n",
        "      if (random_number<class_rules_prob_P2):\n",
        "        self.dna_of_P2.append(1)\n",
        "      else:\n",
        "        self.dna_of_P2.append(0)\n",
        "    self.total_confidence = np.nan    \n",
        "    self.total_coverage = np.nan    \n",
        "    self.no_of_CSRs = np.nan\n",
        "    self.default_class_label = np.nan\n",
        "  \n",
        "\n",
        "  def show_chromosome(self):\n",
        "    print(*self.dna_of_P2, sep = \", \") \n",
        "    \n",
        "\n",
        "  def show_CR(self):\n",
        "    print(*self.dna_of_P2, sep = \", \")     \n",
        "    print('total_confidence = '+str(self.total_confidence))    \n",
        "    print('total_coverage = '+str(self.total_coverage))    \n",
        "    print('no_of_CSRs = '+str(self.no_of_CSRs))\n",
        "\n",
        "\n",
        "  def fitness_calculation_P2(self,experimental_dataset,fold_no,sorted_population_from_P1_MOGA):\n",
        "    flag_list =  [False for i in range(0,experimental_dataset.no_of_records_in_train_list[fold_no])]\n",
        "    rule_list = [-1 for i in range(0,experimental_dataset.no_of_records_in_train_list[fold_no])]\n",
        "    Coverage = 0\n",
        "    for record_no in range(0, experimental_dataset.no_of_records_in_train_list[fold_no]):\n",
        "      for gene_no in range(0, len(self.dna_of_P2)):\n",
        "        if(self.dna_of_P2[gene_no]==1):\n",
        "          CSR = sorted_population_from_P1_MOGA.chromosomes[gene_no]\n",
        "          # flag_list[record_no]=CSR.check_coverage_of_a_record_by_a_chromosome(experimental_dataset,fold_no,record_no)\n",
        "          if(record_no in CSR.list_of_records_covered):\n",
        "            flag_list[record_no] = True\n",
        "          if(flag_list[record_no] == True):\n",
        "            Coverage = Coverage + 1\n",
        "            rule_list[record_no] = gene_no \n",
        "            break\n",
        "    # print('Coverage = '+str(Coverage))\n",
        "    # print(*rule_list, sep = \", \") # for testing\n",
        "\n",
        "    # class_label_counter = []\n",
        "    # print(experimental_dataset.no_of_classes[fold_no]) #for testing\n",
        "    #for class_no in range(0, experimental_dataset.no_of_classes[fold_no]):\n",
        "      #class_label_counter.append(0)\n",
        "    class_label_counter =  [0 for i in range(0,experimental_dataset.no_of_classes[fold_no])]\n",
        "    for record_no in range(0, experimental_dataset.no_of_records_in_train_list[fold_no]):\n",
        "      if(rule_list[record_no] == -1):\n",
        "        for class_no in range(0, experimental_dataset.no_of_classes[fold_no]):\n",
        "          if(str(experimental_dataset.train_list_with_NaN[fold_no].iat[record_no,experimental_dataset.no_of_attributes-1]) == str(experimental_dataset.class_labels[fold_no][class_no])):\n",
        "            class_label_counter[class_no] = class_label_counter[class_no] + 1\n",
        "    max_class_counter = 0\n",
        "    self.default_class_label = np.nan\n",
        "    for class_no in range(0, experimental_dataset.no_of_classes[fold_no]):\n",
        "      # print('class_label_counter[class_no] = '+str(class_label_counter[class_no]))# for testing\n",
        "      if(max_class_counter<class_label_counter[class_no]):\n",
        "        max_class_counter=class_label_counter[class_no]\n",
        "        self.default_class_label = experimental_dataset.class_labels[fold_no][class_no]\n",
        "    # print('default_class_label = '+str(default_class_label))\n",
        "\n",
        "    no_of_match = 0\n",
        "    for record_no in range(0, experimental_dataset.no_of_records_in_train_list[fold_no]):\n",
        "      if(rule_list[record_no] == -1):\n",
        "        if(str(self.default_class_label) == str(experimental_dataset.train_list_with_NaN[fold_no].iat[record_no,experimental_dataset.no_of_attributes-1])):\n",
        "          no_of_match = no_of_match + 1\n",
        "      else:\n",
        "        if(str(sorted_population_from_P1_MOGA.chromosomes[rule_list[record_no]].class_label_of_chromosome) == str(experimental_dataset.train_list_with_NaN[fold_no].iat[record_no,experimental_dataset.no_of_attributes-1])):\n",
        "          no_of_match = no_of_match + 1\n",
        "    # print('no_of_match = '+str(no_of_match))\n",
        "\n",
        "    self.total_confidence = no_of_match/experimental_dataset.no_of_records_in_train_list[fold_no]\n",
        "    #print('total_confidence = '+str(self.total_confidence))\n",
        "    self.total_coverage = Coverage/experimental_dataset.no_of_records_in_train_list[fold_no]\n",
        "    #print('total_coverage = '+str(self.total_coverage))\n",
        "    self.no_of_CSRs = self.dna_of_P2.count(1)\n",
        "    #print('no_of_CSRs = '+str(self.no_of_CSRs))\n",
        "\n",
        "\n",
        "  def calculate_testing_accuracy(self,experimental_dataset,fold_no):\n",
        "    flag_list =  [False for i in range(0,experimental_dataset.no_of_records_in_test_list[fold_no])]\n",
        "    rule_list = [-1 for i in range(0,experimental_dataset.no_of_records_in_train_list[fold_no])]\n",
        "    Coverage = 0\n",
        "    for record_no in range(0, experimental_dataset.no_of_records_in_test_list[fold_no]):\n",
        "      for gene_no in range(0, len(self.dna_of_P2)):\n",
        "        if(self.dna_of_P2[gene_no]==1):\n",
        "          CSR = self.sorted_population_from_P1_MOGA.chromosomes[gene_no]\n",
        "          flag_list[record_no]=CSR.check_coverage_of_a_test_record_by_a_chromosome(experimental_dataset,fold_no,record_no)\n",
        "          if(flag_list[record_no] == True):\n",
        "            Coverage = Coverage + 1\n",
        "            rule_list[record_no] = gene_no \n",
        "            break\n",
        "\n",
        "    no_of_match = 0\n",
        "    for record_no in range(0, experimental_dataset.no_of_records_in_test_list[fold_no]):\n",
        "      if(rule_list[record_no] == -1):\n",
        "        if(str(self.default_class_label) == str(experimental_dataset.test_list_with_NaN[fold_no].iat[record_no,experimental_dataset.no_of_attributes-1])):\n",
        "          no_of_match = no_of_match + 1\n",
        "      else:\n",
        "        if(str(self.sorted_population_from_P1_MOGA.chromosomes[rule_list[record_no]].class_label_of_chromosome) == str(experimental_dataset.test_list_with_NaN[fold_no].iat[record_no,experimental_dataset.no_of_attributes-1])):\n",
        "          no_of_match = no_of_match + 1\n",
        "\n",
        "    self.test_accuracy = no_of_match/experimental_dataset.no_of_records_in_test_list[fold_no]\n",
        "    print('test_accuracy = '+str(self.test_accuracy))\n",
        "    self.test_coverage = Coverage/experimental_dataset.no_of_records_in_test_list[fold_no]\n",
        "    print('test_coverage = '+str(self.test_coverage))\n",
        "    self.no_of_CSRs_in_CR = self.dna_of_P2.count(1)\n",
        "    print('no_of_CSRs_in_CR = '+str(self.no_of_CSRs_in_CR))\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0n0aI18E2_N",
        "colab_type": "text"
      },
      "source": [
        "**Testing_CR_by_Test_Data_set class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "przJtqtdE2Cl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Testing_CR_by_Test_Data_set:\n",
        "  def __init__(self,experimental_dataset,fold_no,chosen_CR):\n",
        "    chosen_CR.calculate_testing_accuracy(experimental_dataset,fold_no)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fSuMdSlsij-",
        "colab_type": "text"
      },
      "source": [
        "**For taking data from CSV files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUlvXVPf3OhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8813c782-de39-4b65-a666-95ac5e976be6"
      },
      "source": [
        "print(\"From .csv (Comma separated file) we are taking it in data frame\") # for testing\n",
        "print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        " \n",
        "github_url = 'https://raw.githubusercontent.com/Dipankar2222/Datasets/master/'\n",
        "\n",
        "# Uncomment the name of the dataset to select it.\n",
        "dataset_name = 'AUTO'\n",
        "#dataset_name = 'credit'\n",
        "#dataset_name = 'dermatology'\n",
        "#dataset_name = 'pima'\n",
        "#dataset_name = 'ecoli'\n",
        "#dataset_name = 'flare'\n",
        "#dataset_name = 'glass'\n",
        "#dataset_name = 'heart_c'\n",
        "#dataset_name = 'haberman'\n",
        "#dataset_name = 'iris'\n",
        "#dataset_name = 'labor'\n",
        "#dataset_name = 'led7digit'\n",
        "#dataset_name = 'monk'\n",
        "#dataset_name = 'newthyroid'\n",
        "#dataset_name = 'sonar'\n",
        "#dataset_name = 'vehicle'\n",
        "#dataset_name = 'vowel'\n",
        "#dataset_name = 'wine'\n",
        "#dataset_name = 'wisconsin'\n",
        "#dataset_name = 'yeast'                   \n",
        "#dataset_name = 'zoo'\n",
        "\n",
        "print ('Dataset') # for testing\n",
        "print (dataset_name)# for testing\n",
        "print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "\n",
        "# Uncomment the name of the file_name to select it.\n",
        "file_name = 'automobile'\n",
        "#dataset_name = 'credit'\n",
        "#dataset_name = 'dermatology'\n",
        "#dataset_name = 'pima'\n",
        "#dataset_name = 'ecoli'\n",
        "#dataset_name = 'flare'\n",
        "#dataset_name = 'glass'\n",
        "#dataset_name = 'heart_c'\n",
        "#dataset_name = 'haberman'\n",
        "#dataset_name = 'iris'\n",
        "#dataset_name = 'labor'\n",
        "#dataset_name = 'led7digit'\n",
        "#dataset_name = 'monk'\n",
        "#dataset_name = 'newthyroid'\n",
        "#dataset_name = 'sonar'\n",
        "#dataset_name = 'vehicle'\n",
        "#dataset_name = 'vowel'\n",
        "#dataset_name = 'wine'\n",
        "#dataset_name = 'wisconsin'\n",
        "#dataset_name = 'yeast'                   \n",
        "#dataset_name = 'zoo'  \n",
        "\n",
        "dataset_number = '1' # Choose a number between 1 and 10\n",
        "\n",
        "train_list = [] # train_list stores 10 train dataframes\n",
        "test_list = [] # train_list stores 10 test dataframes\n",
        "\n",
        " \n",
        "# Fetching data from github and storing into train_list and test_list\n",
        "for i in range(1, 11):\n",
        "    train_list.append(pd.read_csv(github_url + dataset_name + '/' + file_name + dataset_number + '/INPUT_FILES/' + file_name + dataset_number + '-10-' + str(i) + 'tra.dat', header = None))\n",
        "    test_list.append(pd.read_csv(github_url + dataset_name + '/' + file_name + dataset_number + '/INPUT_FILES/' + file_name + dataset_number + '-10-' + str(i) + 'tst.dat', header = None))\n",
        "\n",
        "\n",
        "attribute_information = pd.read_csv(github_url + dataset_name + '/' + file_name + dataset_number + '/INPUT_FILES/Attribute_information.data', header = None)\n",
        "\n",
        "# print(\"Train data of 1st fold\") # for testing\n",
        "# print(train_list[0].to_string()) # for testing\n",
        "# print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "# print(\"Test data of 1st fold\") # for testing\n",
        "# print(test_list[0].to_string()) # for testing\n",
        "# print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "# print(\"Attribute information\") # for testing\n",
        "# print(attribute_information.to_string()) # for testing\n",
        "# print(\"---------------------------------------------------------------------------------------\") # for testing\n",
        "\n",
        "experimental_dataset = Dataset(train_list,test_list,attribute_information) \n"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From .csv (Comma separated file) we are taking it in data frame\n",
            "---------------------------------------------------------------------------------------\n",
            "Dataset\n",
            "AUTO\n",
            "---------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmkGqABgsvMJ",
        "colab_type": "text"
      },
      "source": [
        "**For Execution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XiUfYJYfwF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6808a17d-0eb7-4f0f-8490-bdf3137afa29"
      },
      "source": [
        "fraction_of_training_data = 0.1\n",
        "# print('fraction_of_training_data='+ str(fraction_of_training_data))\n",
        "initial_popultion_list = []\n",
        "# for fold_no in range(0, 10): \n",
        "for fold_no in range(0, 1): # for testing \n",
        "  initial_population = Population()\n",
        "  initial_population.set_values(fraction_of_training_data, experimental_dataset,fold_no)\n",
        "  initial_popultion_list.append(initial_population)\n",
        "\n",
        "max_number_of_generation_of_BPMOGA=1000\n",
        "max_number_of_generation_of_P1MOGA=50\n",
        "max_number_of_generation_of_P2MOGA=50\n",
        "size_of_initial_population_of_P2MOGA=20\n",
        "min_cross_prob_P1=0.5\n",
        "max_cross_prob_P1=0.5\n",
        "min_mu_prob_P1=1\n",
        "max_mu_prob_P1=1\n",
        "min_rule_prob_P2=0.5\n",
        "max_rule_prob_P2=0.5\n",
        "min_cross_prob_P2=0.5\n",
        "max_cross_prob_P2=0.5\n",
        "min_mu_prob_P2=0.1\n",
        "max_mu_prob_P2=0.1  \n",
        "\n",
        "Accuracy_Training_Datasets = []\n",
        "Coverage_Training_Datasets = []\n",
        "Number_of_CSRs_Training_Datasets = []\n",
        "\n",
        "# for fold_no in range(0, 10): \n",
        "for fold_no in range(0, 1): # for testing \n",
        "  bi_phased_MOGA = Bi_Phased_MOGA(experimental_dataset,fold_no,initial_popultion_list[fold_no],max_number_of_generation_of_BPMOGA,max_number_of_generation_of_P1MOGA,max_number_of_generation_of_P2MOGA,size_of_initial_population_of_P2MOGA,fraction_of_training_data,min_cross_prob_P1,max_cross_prob_P1,min_mu_prob_P1,max_mu_prob_P1,min_rule_prob_P2,max_rule_prob_P2,min_cross_prob_P2,max_cross_prob_P2,min_mu_prob_P2,max_mu_prob_P2)\n",
        "  sorted_population_of_CR = bi_phased_MOGA.CRs_of_BPMOGA.sortingCRs()  \n",
        "  chosen_CR = sorted_population_of_CR.chromosomes_of_P2[0]\n",
        "  Accuracy_Training_Datasets.append(chosen_CR.total_confidence)\n",
        "  Coverage_Training_Datasets.append(chosen_CR.total_coverage)\n",
        "  Number_of_CSRs_Training_Datasets.append(chosen_CR.no_of_CSRs)\n",
        "  test_result = Testing_CR_by_Test_Data_set(experimental_dataset,fold_no,chosen_CR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Within Bi_Phased_MOGA class\n",
            "fold_no =0\n",
            "counter =0\n",
            "Within P1_MOGA class\n",
            "generationP1 =0\n",
            "generationP1 =1\n",
            "generationP1 =2\n",
            "generationP1 =3\n",
            "generationP1 =4\n",
            "generationP1 =5\n",
            "generationP1 =6\n",
            "generationP1 =7\n",
            "generationP1 =8\n",
            "generationP1 =9\n",
            "generationP1 =10\n",
            "generationP1 =11\n",
            "generationP1 =12\n",
            "generationP1 =13\n",
            "generationP1 =14\n",
            "generationP1 =15\n",
            "generationP1 =16\n",
            "generationP1 =17\n",
            "generationP1 =18\n",
            "generationP1 =19\n",
            "generationP1 =20\n",
            "generationP1 =21\n",
            "generationP1 =22\n",
            "generationP1 =23\n",
            "generationP1 =24\n",
            "generationP1 =25\n",
            "generationP1 =26\n",
            "generationP1 =27\n",
            "generationP1 =28\n",
            "generationP1 =29\n",
            "generationP1 =30\n",
            "generationP1 =31\n",
            "generationP1 =32\n",
            "generationP1 =33\n",
            "generationP1 =34\n",
            "generationP1 =35\n",
            "generationP1 =36\n",
            "generationP1 =37\n",
            "generationP1 =38\n",
            "generationP1 =39\n",
            "generationP1 =40\n",
            "generationP1 =41\n",
            "generationP1 =42\n",
            "generationP1 =43\n",
            "generationP1 =44\n",
            "generationP1 =45\n",
            "generationP1 =46\n",
            "generationP1 =47\n",
            "generationP1 =48\n",
            "generationP1 =49\n",
            "Within P2_MOGA class\n",
            "Generation of P2_MOGA =0\n",
            "Generation of P2_MOGA =1\n",
            "Generation of P2_MOGA =2\n",
            "Generation of P2_MOGA =3\n",
            "Generation of P2_MOGA =4\n",
            "Generation of P2_MOGA =5\n",
            "Generation of P2_MOGA =6\n",
            "Generation of P2_MOGA =7\n",
            "Generation of P2_MOGA =8\n",
            "Generation of P2_MOGA =9\n",
            "Generation of P2_MOGA =10\n",
            "Generation of P2_MOGA =11\n",
            "Generation of P2_MOGA =12\n",
            "Generation of P2_MOGA =13\n",
            "Generation of P2_MOGA =14\n",
            "Generation of P2_MOGA =15\n",
            "Generation of P2_MOGA =16\n",
            "Generation of P2_MOGA =17\n",
            "Generation of P2_MOGA =18\n",
            "Generation of P2_MOGA =19\n",
            "Generation of P2_MOGA =20\n",
            "Generation of P2_MOGA =21\n",
            "Generation of P2_MOGA =22\n",
            "Generation of P2_MOGA =23\n",
            "Generation of P2_MOGA =24\n",
            "Generation of P2_MOGA =25\n",
            "Generation of P2_MOGA =26\n",
            "Generation of P2_MOGA =27\n",
            "Generation of P2_MOGA =28\n",
            "Generation of P2_MOGA =29\n",
            "Generation of P2_MOGA =30\n",
            "Generation of P2_MOGA =31\n",
            "Generation of P2_MOGA =32\n",
            "Generation of P2_MOGA =33\n",
            "Generation of P2_MOGA =34\n",
            "Generation of P2_MOGA =35\n",
            "Generation of P2_MOGA =36\n",
            "Generation of P2_MOGA =37\n",
            "Generation of P2_MOGA =38\n",
            "Generation of P2_MOGA =39\n",
            "Generation of P2_MOGA =40\n",
            "Generation of P2_MOGA =41\n",
            "Generation of P2_MOGA =42\n",
            "Generation of P2_MOGA =43\n",
            "Generation of P2_MOGA =44\n",
            "Generation of P2_MOGA =45\n",
            "Generation of P2_MOGA =46\n",
            "Generation of P2_MOGA =47\n",
            "Generation of P2_MOGA =48\n",
            "Generation of P2_MOGA =49\n",
            "Maximum total confidence =0.842391304347826\n",
            "Maximum total coverage =1.0\n",
            "Minimum number of CSRs =31\n",
            "counter =1\n",
            "Within P1_MOGA class\n",
            "generationP1 =0\n",
            "generationP1 =1\n",
            "generationP1 =2\n",
            "generationP1 =3\n",
            "generationP1 =4\n",
            "generationP1 =5\n",
            "generationP1 =6\n",
            "generationP1 =7\n",
            "generationP1 =8\n",
            "generationP1 =9\n",
            "generationP1 =10\n",
            "generationP1 =11\n",
            "generationP1 =12\n",
            "generationP1 =13\n",
            "generationP1 =14\n",
            "generationP1 =15\n",
            "generationP1 =16\n",
            "generationP1 =17\n",
            "generationP1 =18\n",
            "generationP1 =19\n",
            "generationP1 =20\n",
            "generationP1 =21\n",
            "generationP1 =22\n",
            "generationP1 =23\n",
            "generationP1 =24\n",
            "generationP1 =25\n",
            "generationP1 =26\n",
            "generationP1 =27\n",
            "generationP1 =28\n",
            "generationP1 =29\n",
            "generationP1 =30\n",
            "generationP1 =31\n",
            "generationP1 =32\n",
            "generationP1 =33\n",
            "generationP1 =34\n",
            "generationP1 =35\n",
            "generationP1 =36\n",
            "generationP1 =37\n",
            "generationP1 =38\n",
            "generationP1 =39\n",
            "generationP1 =40\n",
            "generationP1 =41\n",
            "generationP1 =42\n",
            "generationP1 =43\n",
            "generationP1 =44\n",
            "generationP1 =45\n",
            "generationP1 =46\n",
            "generationP1 =47\n",
            "generationP1 =48\n",
            "generationP1 =49\n",
            "Within P2_MOGA class\n",
            "Generation of P2_MOGA =0\n",
            "Generation of P2_MOGA =1\n",
            "Generation of P2_MOGA =2\n",
            "Generation of P2_MOGA =3\n",
            "Generation of P2_MOGA =4\n",
            "Generation of P2_MOGA =5\n",
            "Generation of P2_MOGA =6\n",
            "Generation of P2_MOGA =7\n",
            "Generation of P2_MOGA =8\n",
            "Generation of P2_MOGA =9\n",
            "Generation of P2_MOGA =10\n",
            "Generation of P2_MOGA =11\n",
            "Generation of P2_MOGA =12\n",
            "Generation of P2_MOGA =13\n",
            "Generation of P2_MOGA =14\n",
            "Generation of P2_MOGA =15\n",
            "Generation of P2_MOGA =16\n",
            "Generation of P2_MOGA =17\n",
            "Generation of P2_MOGA =18\n",
            "Generation of P2_MOGA =19\n",
            "Generation of P2_MOGA =20\n",
            "Generation of P2_MOGA =21\n",
            "Generation of P2_MOGA =22\n",
            "Generation of P2_MOGA =23\n",
            "Generation of P2_MOGA =24\n",
            "Generation of P2_MOGA =25\n",
            "Generation of P2_MOGA =26\n",
            "Generation of P2_MOGA =27\n",
            "Generation of P2_MOGA =28\n",
            "Generation of P2_MOGA =29\n",
            "Generation of P2_MOGA =30\n",
            "Generation of P2_MOGA =31\n",
            "Generation of P2_MOGA =32\n",
            "Generation of P2_MOGA =33\n",
            "Generation of P2_MOGA =34\n",
            "Generation of P2_MOGA =35\n",
            "Generation of P2_MOGA =36\n",
            "Generation of P2_MOGA =37\n",
            "Generation of P2_MOGA =38\n",
            "Generation of P2_MOGA =39\n",
            "Generation of P2_MOGA =40\n",
            "Generation of P2_MOGA =41\n",
            "Generation of P2_MOGA =42\n",
            "Generation of P2_MOGA =43\n",
            "Generation of P2_MOGA =44\n",
            "Generation of P2_MOGA =45\n",
            "Generation of P2_MOGA =46\n",
            "Generation of P2_MOGA =47\n",
            "Generation of P2_MOGA =48\n",
            "Generation of P2_MOGA =49\n",
            "Maximum total confidence =0.842391304347826\n",
            "Maximum total coverage =1.0\n",
            "Minimum number of CSRs =31\n",
            "counter =2\n",
            "Within P1_MOGA class\n",
            "generationP1 =0\n",
            "generationP1 =1\n",
            "generationP1 =2\n",
            "generationP1 =3\n",
            "generationP1 =4\n",
            "generationP1 =5\n",
            "generationP1 =6\n",
            "generationP1 =7\n",
            "generationP1 =8\n",
            "generationP1 =9\n",
            "generationP1 =10\n",
            "generationP1 =11\n",
            "generationP1 =12\n",
            "generationP1 =13\n",
            "generationP1 =14\n",
            "generationP1 =15\n",
            "generationP1 =16\n",
            "generationP1 =17\n",
            "generationP1 =18\n",
            "generationP1 =19\n",
            "generationP1 =20\n",
            "generationP1 =21\n",
            "generationP1 =22\n",
            "generationP1 =23\n",
            "generationP1 =24\n",
            "generationP1 =25\n",
            "generationP1 =26\n",
            "generationP1 =27\n",
            "generationP1 =28\n",
            "generationP1 =29\n",
            "generationP1 =30\n",
            "generationP1 =31\n",
            "generationP1 =32\n",
            "generationP1 =33\n",
            "generationP1 =34\n",
            "generationP1 =35\n",
            "generationP1 =36\n",
            "generationP1 =37\n",
            "generationP1 =38\n",
            "generationP1 =39\n",
            "generationP1 =40\n",
            "generationP1 =41\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}